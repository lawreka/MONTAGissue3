<!DOCTYPE html>
<html>
 <head>
   <meta charset="UTF-8">
 <meta name="viewport" content="width=device-width,initial-scale=1">
   <title>MONTAG Issue 3 Coding Creativity</title>
   <link rel="shortcut icon" href="favicon.ico" type="image/vnd.microsoft.icon">
   <link rel="stylesheet" href="stylesheet.css" type="text/css">
   <script src="script.js"></script>
 </head>
 <body onLoad="start()">
   <div id="images">
   </div>
   <div id="text">

    KATHRYN LAWRENCE

      CODING CREATIVITY
      Creativity is one of the greatest mysteries of the human experience.
      Artists and scientists alike have long wondered: where does it come from and how does it work?
      Creativity is also one of the few things we can point to that makes us unique as humans. Which is why it's so thrilling, and terrifying, to think that artificial intelligence could become creative – if it hasn't already.

      The myths of creativity
      The ancient theory was that
      creativity came from a higher power
      than humanity: that it was bestowed
      upon our puny human consciousness
      from some kind of infinite spirit,
      or universal force known to most
      religions as their flavor of God.

      Writer Elizabeth Gilbert touches on
      this theory in her 2009 TED Talk,
      "Your elusive creative genius." She
      explains that in ancient Greece
      and Rome "genius" did not live
      inside of individual people, but
      was a spirit from the gods that
      lived in the walls of an artist's
      studio. The Renaissance flipped
      this idea on its head and centered
      people as creative geniuses (your
      Michelangelos, da Vincis, and other
      great men of history). She thinks
      that this is part of what puts
      pressure on modern artists that
      drives them to self-destruction,
      and questions whether we should
      go back to some form of this
      ancient understanding of it
      as an external force when we
      investigate the source of
      creativity.

      Today, it's a popular theory that
      creativity comes out of problemsolving and a need to defy known
      rules or conventions. In this
      theory, creativity is credited
      with all great breakthroughs in
      science, medicine, and technology.

      "How does a grapefruit-sized heap
      of meat crackling with electricity
      conceive of mathematical theorems,
      create beautiful art, discover the
      laws of nature, invent kitesurfing,
      and design buildings that look
      like sea shells?" – Arne Dietrich,
      "Where does 'creativity' happen in
      your brain?"

      Arne Dietrich's work on the
      cognitive neuroscience of
      creativity defines creativity as
      "The ability to produce work that
      is both novel (i.e., original,
      unexpected) and appropriate (i.e.,
      useful, adaptive concerning task
      constraints)...Creativity is the
      epitome of cognitive flexibility.
      The ability to break conventional
      or obvious patterns of thinking,
      adopt new and/or higher order
      rules, and think conceptually and
      abstractly is at the heart of any
      theory of creativity."

      Dietrich and many, many other teams
      of neuroscientists have tried to
      pin down the location of creativity
      in the brain, but haven't found a
      single spot that lights up when
      having creative ideas, or that
      you could apply electrodes to and
      stimulate to produce creative
      genius. Creativity uses almost
      every part of the brain.

      All of this to say that we still
      don't fully understand creativity
      at all, but that is part of why we
      think it makes us special. Some are
      afraid that creativity may be the
      only thing standing between us and
      robots taking
      our jobs.

      Artificial intelligence developing
      creativity is often one of the first
      signs in science fiction that we are
      truly fucked.

      Painting robots, fiction and
      facts

      In an iconic scene from I, Robot,
      Will Smith's detective Del Spooner
      is interrogating a robot that he
      believes has murdered its creator.
      He asserts that robots don't
      have emotions, and are therefore
      incapable of producing great works
      of art. The robot asks, "Can you?"
      It's a great question, because it
      makes us wonder what standard we
      should hold artificial intelligence
      to when attempting to define its
      capacity for creativity. There
      are plenty of bad (human) artists
      in the world, why should we
      expect robot artists to be (evil)
      geniuses?

      Most people have heard of the
      Turing Test, but not the Lovelace
      Test. It's named after Ada
      Lovelace, the original programmer
      of Charles Babbage's "Analytical
      Engine," the theoretical model of
      a functional computer which was
      conceived 100 years before the
      Turing machine.

      Lovelace famously said, "The
      Analytical Engine has no
      pretensions whatever to originate
      anything. It can do [only] whatever
      we know how to order it to
      perform," meaning that it is not
      possible for computers to have a
      creative output.

      The Turing Test tests if computers
      are capable of emulating humans,
      and the Lovelace Test tests if they
      are capable of creativity. In 1994,
      professor of cognitive science
      Margaret A. Boden wrote in the
      introduction to the book, Artificial
      Intelligence and Creativity: An
      Interdisciplinary Approach, a
      series of questions she called
      "Lovelace-questions."

      The Lovelace-questions are as
      follows:

      1.	"whether computational concepts
      can help us understand how human
      creativity is possible"

      2.	"whether computers (now or in
      the future) could ever do things
      which at least appear to be
      creative"

      3.	"whether a computer could ever
      appear to recognize creativity"

      4.	"whether computers themselves
      could ever really be creative
      (as opposed to merely producing
      apparently creative performance
      whose originality is wholly due
      to the human programmer)."
And all of the answers to these
      questions appear to be yes.

      In her later (1998) paper,
      "Creativity and artificial
      intelligence," she explains
      artificial intelligence can create
      new ideas in three ways: "by
      producing novel combinations of
      familiar ideas; by exploring the
      potential of conceptual spaces;
      and by making transformations
      that enable to the generation of
      previously impossible ideas...
      The ultimate vindication of AI
      creativity would be a program
      that generated novel ideas which
      initially perplexed or even
      repelled us, but which was able to
      persuade us that they were indeed
      valuable. We are a very long way
      from that."

      Of course, back in 1998, it may
      have seemed like we were a long way
      from a lot of technology we take
      for granted in the 21st century.
      1998 was the year Google was
      founded, most people were accessing
      Usenet via Netscape or Internet
      Explorer on their Windows 98 PCs.

      Boden has since acknowledged, in a
      2015 View for the MIT Technology
      Review, that even though artificial
      intelligence is capable of creating
      great abstract works of art,
      the lack of cultural contextual
      knowledge that it has is its
      greatest weakness. AI can make good
      art now, but it can't yet convince
      us that it's good.

      Matthew Putman, CEO of Nanotronics,
      has expressed a similar opinion in
      his essay, "Artificial Objectivity,"
      that robots can't be great artists
      because they can't appraise their
      own work: "For art, objectively
      good is distinguished from
      subjectivity only by universal
      human values."

      Luckily, the responsibility for
      creation and appraisal of art have
      never fallen to the single human
      artist anyway... well, maybe one:

      "You know it's ART, when the check
      clears" - Andy Warhol

      The Lovelace and Warhol definitions
      of art rely on the human critic
      being convinced: in the Lovelace
      test, they must be convinced that
      the programming is not entirely
      responsible for the output and that
      the output is satisfactory, and for
      the Warhol test, they have to be
      willing to buy it.

      So... bring on the robot art
      fairs!

      AARON is a painting robot that,
      according to the MIT Technology
      Review, had been collaborating with
      artist Harold Cohen since 1973.
      As early as the 1980s, Cohen was
      quoted saying he was "the only
      artist who would ever be able to
      have a posthumous exhibition of new
      works created entirely after his
      own death." Cohen passed in April
      of 2016, and, sadly, AARON has not
      continued to make new work, but
      this creative collaboration between
      man and machine was one of the
      first instances of robot paintings
      shown in galleries (although shows
      featuring work by both Cohen and
      AARON are still listed under "Oneperson exhibitions" in Cohen's
      biography).

      The Review argues that AARON was
      a true artist working under Cohen
      in the lineage of Renaissance
      painters, whose works would often
      be executed by teams of apprentices
      and copyists, but still credited to
      the master. However, Cohen himself
      has been quoted saying that a robot
      would have to develop a sense of
      self in order to become creative
      in the same sense that humans are
      creative.

      One of the things that was missing
      in AARON's painting process was
      visual feedback - a capability
      that many of today's artificially
      intelligent painting robots have.

      Pindar Van Arman's CloudPainter is
      equipped with a custom 3D printed
      paint head, two robotics arms, deep
      learning, artificial intelligence,
      and computational creativity to
      compose its own original artwork.
      VICE Video's coverage of his robots
      show CloudPainter using style
      transfer, combining photographs
      and painting styles to create new
      portraits.

      Simon Colton's painting robot
      called The Painting Fool can read
      emotions from photographs and use
      several different painting styles
      to convey that emotion in its
      portraiture. It can also read, and
      has used keywords from the news
      to create a collage about war. It
      even has a setting in which, when
      overwhelmed by too many negative
      keywords, it will refuse to paint.

      A General Adversarial Network
      (or GAN) trained by the Art & AI
      Laboratory at Rutgers University,
      trained on over 80,000 paintings,
      created abstract paintings that
      were indistinguishable from
      humans'. When placed alongside
      images of real Abstract
      Expressionist paintings and work
      from Art Basel 2016, critics had
      to answer how the paintings made
      them feel, inspired, or if they
      found the paintings complex or
      novel (and remember, novelty is one
      of the keys of creativity!) The
      results: "Not only could the human
      evaluators not tell which images
      were AI-created, in many cases they
      rated the AI’s artwork higher than
      the humans’."

      How fucked are we?

      Popular opinion seems to be
      that yes, robots with artificial
      intelligence are creative, but
      only as collaborators. So we return
      once again to the question of what
      creativity is – must it come from a
      singular, creative genius?

      Psychology Today says, "This Makes
      Us Human": the ability to blend
      knowledge, taking old stories
      and new ideas, as the root of
      creativity. Augustin Fuentes,
      author of the book The Creative
      Spark: How Imagination Made Humans
      Exceptional, equates wisdom and
      creativity, and uses evolutionary
      psychology to back up his theory
      that creative collaboration is what
      made human society possible today.
      Else how could "fangless, clawless,
      hornless, naked upright primates"
      accomplish so much?

      And perhaps creative collaboration
      is what will help evolve artificial
      intelligence as well. We shouldn't
      worry about AI painters demanding
      attribution (much less taking over
      the world) until we have I, Robot
      levels of autonomous artificial
      intelligence running amok.

      For now, our fragile human egos are
      safe, if we believe that artificial
      intelligence is a collaborative
      force; but that actually makes them
      just like us already.
      If we believe that the cult of
      the genius has passed, and that
      collaborative, not individual,
      creativity is the true measure of
      human intelligence, then AI has
      already more than sufficiently filled
      that role.

      Or if we return to the theory that
      creativity comes from some kind of
      divine intervention, then from the
      perspective of AI, we are the gods.

JOE SPARROW


      TODAY’S DYSTOPIA: THEY LIVE
      The world often feels like a dystopia at the moment. In MONTAG's Today's Dystopia series,
      our writers take a sideways look at fictional dystopias, compare them to reality, and ask:
      how close are we to living in tomorrow's dystopias today? Joe Sparrow sighs deeply and
      compares classic low-budget sci-fi movie They Live with the real world...

      Pop culture allegories don’t get
      much more “pop” than They Live.
      Its main star is a pro wrestler,
      it’s directed like a low-budget
      80s MTV video, the script is curt,
      unfussy and full of holes. There’s
      a lengthy, seemingly gratuitous
      and unintentionally hilarious six
      minute street fight scene - over a
      pair of sunglasses - in the middle
      of it all.

      And yet with each year that passes
      since its 1988 release, They Live
      reveals itself more and more to
      be a stiletto-sharp appraisal of
      the consumerism, capitalism, and
      inequality that saturates society
      – and how it is slowly, silently
      strangling us, right under our
      noses.

      They Live is as much of a horror
      movie as director John Carpenter’s
      other more famous films, The Thing
      and Halloween. But instead of
      supernatural shocks and spills, the
      viewer might reasonably conclude
      that in They Live the horrorshow
      feels real, and not only are we
      living in it every day, but we’re
      helping it consume us.

      The film’s premise is as
      stupendously silly as it is simple:
      a homeless, jobless man played
      by wrestler “Rowdy” Roddy Piper
      searches for employment in LA. He’s
      at the bottom of the heap, as his
      surname, Nada – meaning “Nothing”
      in Spanish – makes clear, and his
      struggle to find work is juxtaposed
      with the wealth and rampant
      consumerism of Reagan’s 1980s.

      Having broken into a closed church,
      John finds an unmarked cardboard box
      full of sunglasses. In the glaring
      Los Angeles sunshine, he slips a
      pair on – and to his horror, they
      reveal the real world to him for
      the very first time.

      Does any of what John sees sound
      familiar? How about a gigantic
      wealth gap between the gilded top
      10% and a vast population who
      don’t know when they’ll be paid
      next? A bloated middle class who
      believe that ultra-wealth is just
      within their grasp if only they
      keep working themselves into the
      ground? A bombardment of multimedia
      messaging seducing us to part with
      cash for products that’ll get us
      that bit closer to the elite? A
      corrupt ruling class that promises
      us everything is better than ever?

      Slip on your sunglasses as we peer
      into the cold heart of today and
      compare how close today is to the
      dystopia of They Live. We’ll mark
      each scenario out of five sunglasses
      (🕶), in honour of John Nada’s
      iconic shades.

      Hyper-commerciality and
      persuasion to conform and
      spend: 🕶🕶🕶🕶

      When John Nada dons the sunglasses
      in They Live, they reveal the true
      message on billboards: the stark
      command OBEY. Ads featuring bikiniclad babes are a front for MARRY
      AND REPRODUCE; lifestyle magazine
      covers reveal CONFORM; radio
      transmitters drone the message
      SLEEP…. SLEEP… 24 hours a day.

      John Carpenter said that They Live
      sprung from a realisation that the
      apparently bubbling economy and
      positive messaging from politicians
      had a distantly-connected flip side:
      he was constantly being pitched
      products.

      "I began watching TV again. I
      quickly realized that everything
      we see is designed to sell us
      something... It's all about wanting
      us to buy something. The only thing
      they want to do is take our money.”

      Nearly 30 years after They Live was
      filmed, what do today’s creative
      minds think about the persuasively
      commercial nature of media today?

      Edgar Wright, director of hit
      movies Baby Driver and Shaun of the
      Dead, tweeted, “If you remade They
      Live now, the twist would be that
      you don’t even need the glasses.”

      But why? Maybe it's because the
      tools we use to interact with the
      world are so blatantly manipulative
      and the people that use them are so
      blatant in their manipulation.

      Facebook’s “Data God” was Jeffrey
      Hammerbacher. He figured out how to
      slice up all the data they have on
      you, which then helped the social
      media giant make more money than
      all the gods combined.

      He left Facebook because he
      was tired of seeing, in part,
      creativity drained from the most
      gifted people. His off-the-cuff
      observation - “the best minds of
      my generation… are thinking about
      how to make people click ads. That
      sucks.” - has become a defining
      comment on our digital age.

      There's an icky amorality to the
      work of these brightest minds that
      create an app that values your
      time; which is to say, all of them.

      By eagerly copying the technology
      that keeps punters gambling on
      video slot machines, they literally
      want to make you addicted to their
      app. Why? To see more adverts,
      mainly.

      And Banksy, whose brash peoplepleasing work puts anti-authority
      messages in front of millions, has
      some thoughts on advertising:

      “The thing I hate the most about
      advertising is that it attracts all
      the bright, creative and ambitious
      young people, leaving us mainly
      with the slow and self-obsessed to
      become our artists. Modern art is a
      disaster area. Never in the field of
      human history has so much been used
      by so many to say so little.”
      OBEY, indeed.

      A super-elite using
      technology to enslave
      humanity: 🕶🕶🕶

      John’s magic sunglasses allow him
      to see that the wealthy people
      around him are actually aliens
      who have secretly assimilated
      society, assumed wealthy positions
      of authority, and put in place a
      scheme to control the other 90%
      through media, advertising and
      branding.

      So far, so preposterous – although
      these out-there ideas are fairly
      well-worn IRL, too.

      Ex-Coventry City goalkeeper, exBBC broadcaster, self-proclaimed
      “son of God”
      and conspiracy
      theorist supremo
      David Icke
      believes that the
      world’s elite
      - notably, HRH
      Queen Elizabeth
      II – are part of
      a shape-shifting
      reptilian race
      who enslave the
      rest of us.

      Except, wake up
      sheeple: it’s
      actually our
      celebs who are
      in charge, and
      apparently it’s
      mainly female
      music stars. A
      quick Google
      reveals that, to
      some conspiracy
      theorists,
      Beyonce is Satan;
      Rihanna, Miley
      Cyrus, Katy
      Perry, Nicki
      Minaj and Shakira
      are lizards;
      and that there
      must be a lot
      of evenings
      put aside for
      world-domination
      planning in the
      Knowles-Carter
      household, as
      Jay-Z is also
      an Illuminati
      puppet.
      OK, this is all
      ludicrous. But
      if the powerful,
      wealthy, and
      hyper-influential
      cabal of modern
      celebrity family
      empires like the
      Kardashians or the Hadids could
      be considered to be our social
      “super elite,” then their mastery
      of social media is – in a small
      way - “controlling” the hundreds of
      millions that elect to follow their
      idols.

      And whenever one of these elite
      convinces a follower to buy the
      now-ubiquitous fitness teas, waist
      trainers and teeth whiteners that
      they advertise, they trap one more
      puny, working-class human into a
      cycle of financial dependence.
      OBEY.

      Magic sunglasses that reveal
      the truth of the world around
      you: 🕶🕶🕶

      There is already technology to
      rival the most iconic of They
      Live’s props.
      When the viewer finds out that
      billboards are duping our hero,
      the most striking realisation –
      after taking on board the huge plot
      twist – is an understanding of just
      how surrounded we are by adverts,
      billboards, images, and signage
      imploring us to buy... stuff.

      Brand Killer is a custom Augmented
      Reality headset that scans the
      world in front of the wearer,
      recognises any brand logos that
      stray into their field of vision –
      and then blurs them out.
      Brand Killer is ad-blocker IRL, and
      it answers an utterly compelling
      question: what would your world
      be like if it
      was completely
      unsullied by brand
      logos and adverts?

      However - and
      now, please do
      not adjust your
      aluminium foil
      hat - Brand
      Killer suggests
      a way our tech
      overlords could
      grab a little more
      control over us.

      Soon, AR glasses
      will be everyday
      tech. So what if
      Brand Killer was
      used nefariously,
      and instead of
      spotting ads and
      blocking them,
      it replaced ads
      with ads tailored
      specifically to
      us instead? You
      couldn't escape.
      And why would you
      want to?

      OBEY.

      Overall score: 🕶🕶🕶🕶

      They do, indeed,
      Live! (Kind of.)

      OK, maybe there
      aren’t aliens
      enslaving us
      (sorry, David
      Icke) but we
      certainly do seem
      to be our own
      worst enemies
      with regards to
      allowing our
      intentions to be
      "influenced" by
      those we follow online.
      Maybe, then, today’s version of
      popping on John Nada’s glasses is
      to voluntarily switch on flight
      mode, and step away from the
      internet for a few days: and only
      then can we see the unfiltered truth
      - and finally OBEY ourselves.
J.K. MITTWOCH

      MONTAG FICTION: KOMFORT FUTURE TECHNOLOGIES

      This MONTAG.WTF feature sponsored by Komfort Future Technologies Ltd.

      Shop these must-have Komfort Future Technologies at your local Sansmams or 10^100 online retailers.

      The design of everyday things has reached its pinnacle;
      life is comfortable and ergonomic thanks to Komfort
      Future Technologies products.
      Instead of dealing with the mounting problems of the overdeveloped world by alleviating
      them with technology, they are simply made bearable through the miracle of impeccable
      product design!

      Living the future is Easy,
      with Komfort
      Future
      Technologies!

      The following products have been
      engineered for MAXIMUM LEISURE and
      MINIMUM EFFORT, and are some of
      our favorite recommended staples
      for all households. Whether
      you live in a pod or an urban
      skyfarm, simply download
      the 3D printable files from
      your local registered retailer
      of home goods, and enjoy
      the ease of Komfort Future
      Technologies hot off the maker
      in a snap.

      THE TUBE

      Unfortunately, overdevelopment has given
      our Mother Earth a little indigestion.
      Humanity is just a too-spicy topping on the
      planet pizza, which is why water comes
      out of the tap discolored and off-gassing
      unsavory fumes.

      These little belches make drinking straight
      tap water a big no-no. But home filtration
      tech is too slow! Remember those old water
      pitchers with the charcoal inserts that every
      passive aggressive roommate on the planet
      would refuse to replenish?

      The Tube from Komfort Future Technologies
      has revolutionized water drinking, with a
      hands-free interface and a 20-foot self-
      cleaning piping system.

      Simply connect The Tube to your kitchen or bathroom taps and install
      the business end (that's the part you drink from!) next to your screen
      viewing station of choice. Water will ambiently filter through the
      patented system and store itself for your drinking pleasure.

      To partake, simply tilt your head towards The Tube to dispense
      hydration into your mouth.

      Drinking from The Tube has been proven to increase daily
      hydration by 110%, while saving you time and energy.

      Upgrade The Tube with Komfort Foods Flavor Pax
      now available in Lemon, Pudding, and Salt.

      THE SLEEPER CAR

      Waking up every day and getting out of bed for
      work used to be such a hassle.

      With the patented technology of Komfort Future
      Technologies Sleeper Car, you no longer have to.

      Before retiring to the seductively soft Flying
      Dutchman synthfoam slab for your evening slumber,
      use the integrated maps interface to program your
      workplace location and intended arrival time.

      You'll be ready to get to work having slept through
      your morning commute and bathed in a mist of
      revitalizing antimicrobial gel.

      For an additional boost, upgrade to The Sleeper
      Car CHARGE to infuse your morning mist bath with
      transdermal caffeine. Up and at 'em!

      THE PHOLDER
      Gone are the days of tapping and scrolling by
      hand, and good riddance.

      Generations of people in the age of the smartphone
      developed freakishly muscular hands from constantly
      clutching fragile, glass-screened devices and tapping
      furiously at them 24 hours a day.

      With The Pholder, your hands will stay proportional to
      your body and you never have to worry about dropping
      your costly devices again.

      No matter where you go, your phone will sit at a
      comfortable distance from your face for reference.
      Gaze Activation ensures that the screen is on
      whenever you look at it.

      Plus, The Pholder has several settings for phone
      activities built in, and can be customized to sync with
      the apps and social styles you use most regularly.

      Default functions include:
      • Scrollr, automatic scrolling based on eye-tracking behavior
      • Chekr, automatic opening and re-opening of frequently used apps on a customised timer
      • Likr, automatic posting of approval for content consistent with the user's personal brand data
KATHRYN LAWRENCE

      FUN WITH NEURAL NETWORKS
      Janelle Shane is the reigning queen
      of making funny, silly, and downright
      bizarre texts with neural networks.
      She's an electrical engineer who
      works with holographic laser beams by
      day, and plays with neural networks
      in her spare time.

      Her projects use char-rnn, a type of
      neural network which she explains
      by linking to Andrej Karpathy's
      "The Unreasonable Effectiveness of
      Recurrent Neural Networks," which
      details how recurrent neural networks
      process the data fed into them, such
      as the complete works of William
      Shakespeare, and produce something
      that looks exactly like Shakespeare,
      but is a genuine fake.

      Andrej Karpathy is currently the
      Director of AI at Tesla, and his
      blog and github page have been cited
      by innumerable data scientists,
      hobbyists, and others interested in
      learning about how neural networks
      work and how to set them up themselves
      for fun and profit.

      Janelle Shane's projects started
      going viral in 2017 with a popular
      one being a neural network that
      could design and name paint colors.
      Some of the paint names it invented
      include a drab olive green deemed
      “Clardic Fug,” a pale pink called
      “Bank Butt,” and a light mauve with
      the moniker “Stanky Bean.”

      Her conclusion: the neural network
      has "really really bad ideas" for
      paint names.

      But if you think Clardic Fug, Bank
      Butt, and Stanky Bean are as weird
      as it's going to get, please read
      on.

      What's in a name?

      Names are short and pretty easy for
      a char-rnn network to re-arrange
      and re-combine into something that
      sounds vaguely plausible to us, so
      many of her projects have involved
      naming conventions.

      Cheese Breeze and beer please

      Training the network on 1,500 names
      from the My Little Pony Friendship
      is Magic Wiki, she had one experiment
      naming new My Little Ponies. With
      names
      like
      "Rainbow
      Dash"
      and
      "Fluttershy" already extant in the
      Ponyverse, this one was marked as
      a partial success. While plausible

      ponies
      like
      Sunshine
      Star
      and
      Glowberry were produced, there were
      also ponies like Cheese Breeze,
      Apple Ronch, and Groan.

      A similar project created craft beer
      names, with a delightful degree of
      realism. Look out for the Dang River
      IPA, Frog Trail Amber Ale, and the
      Sir Coffee Stout on your next trip to
      the neural network taproom.

      May the farce be with you

      Another project creating Star Wars
      character
      names
      unsurprisingly
      produced a lot of Siths at the lowest
      creativity levels, including "Darth
      Darth." And wasn't Darth Teen the
      villain in The Force Awakens?

      She also created one for Star Wars
      planets (with extant names like
      "Tatooine," and "Hoth," anything
      is possible) and used Twitterbot
      @i_find_planets to flesh out their
      descriptions. If you haven't had your
      personal planet found, we recommend
      tweeting "Planet, please!" at @i_
      find_planets for a planet of your
      very own.

      Foppin and Popchop

      Shane's project to produce cat names
      was trained on several hundred names
      from a cat rescue in Alabama, and
      several thousand cats registered in
      Toronto, which should have created
      names following North American cat
      naming conventions.

      But she first trained the network on
      the wrong data set, using a list of
      fantasy names by J. R. R. Tolkien,
      George R. R. Martin, and others,
      producing such exquisite cat names
      as Mankith, Belfine Bracken, and Grim
      Wyyne.

      Eventually (when trained on the
      correct data set) this project
      resulted in such suitable names as
      Snox Boops, Foppin, and Mr Gruffles.
      Other cat names that she deemed
      less successful, but we must beg to
      differ: Sofa, Pope, and Pissy.

      She also named guinea pigs for the
      Portland Guinea Pig Rescue: Popchop
      and Fuzzable. If The Adventures of
      Popchop and Fuzzable isn't a buddy
      comedy in the making, what is?

      The best of the rest

      Most people think anything could be
      a band name, and with bands like
      Shpongle, Spoon, and !!! out there,
      it's hard to dispute these neural
      network names' plausibility: The
      Freights (which probably sounds like
      The Shins, but recorded from inside
      a boxcar rolling down a lonely track
      at midnight), Nighty Daggers (maybe
      something like the Arctic Monkeys?
      but with more stabbing), and Skins
      of Space (which was definitely a
      rejected name for the glam rock band
      that would become The Darkness).

      She was also able to name metal
      bands with a huge amount of data
      (100,000 bands including genre and
      country of origin) and I personally
      can't wait to go see Death from the
      Trend, the Black Metal outfit from
      Croatia, next time they tour with
      the Russian Melodic Death Metal band
      Inhuman Sand.

      The show must go on

      A neural network trained
      to
      create
      Broadway
      productions, including
      closing and opening
      dates,
      produced
      plays that were not
      limited
      in
      their
      performances by the
      constraints of linear
      time, or the normal
      rules of decorum in naming
      conventions.

      Results included a comedy entitled
      Butt, which ran for over 7 years and
      was only performed once, and a much
      more successful play called Fart,
      with a 4-year run and performance
      count of 23 times.

      Wise or otherwise

      Three more of her experiments relied
      on tricky human patterns of speech:
      proverbs,
      fortune
      cookies,
      and
      knock-knock jokes.
      Many of the ancient proverbs sound
      like they were dreamed up by the
      Inspirobot and could pass: "No wise
      man ever wishes to be sick." While
      others revealed a strange obsession
      with oxen.
      The fortune cookies produced almost
      no usable answers. But the knockknock joke generator produced this
      laugh-out-loud gem that you
      will definitely want to use at
      parties:

Knock Knock
      Who’s There?
      Ireland
      Ireland who?
      Ireland you money, butt.

      Mastchar-rnn chef

      Saving the best for last, Shane's
      most hilarious project to date was
      trained on 30,000 cookbook recipes,
      and based on Tom Brewe's project
      to create recipes using a neural
      network.

      The results sound like something
      out of the surrealist cookbook by
      Salvador Dali Les Diners de Gala,
      or from the Manifesto of Futurist
      Cooking.

      Combine
      chunks
      sprout clams

      The
      network
      disturbingly
      ingredients:

      1 cup mixture
      1 teaspoon juice
      1 chunks

      and oddly specific
      ones "that you
      could plausibly
      ask for at Whole
      Foods and act
      all disappointed
      when they don’t
      have any" such as
      "milked salt."

      Which combined with
      dubious
      cooking
      instructions
      such
      as
      "Fold water. Roll into small
      cubes." and "Sprout clams; add
      vanilla." to produce the most
      improbable meals since bread in
      a can.

      Just for fun, she once gave her
      cooking network the complete works
      of H. P. Lovecraft, and asked it to
      complete sentences, or start them,
      producing such spooky instructions
      as:

      "Coat apple slices with strange
      things."

      "Cook over medium heat until
      thickened and bubbly. Spoon over
      bizarre eyes."

      "Sometimes, in the throes of a
      nightmare when unseen powers whirl
      one over the roofs of strange dead
      cities
      toward
      the
      grinning
      chasm of
      Nis, it is a relief
      and even a delight
      to make the soup."

      The cake is a lie

      Here's one recipe for a
      "cake":

      BAKED OTHER LIE 1993 CAKE

      appetizers, fish
      8 rounds; chicken
      ¼ lb butter (soaked)
      1 can tomato sauce (½ lb)
      1 salmon steaks sauteed
      ½ teaspoon red pepper, chunked
      1 tablespoon margarine or oil.

      One
      intrepid
      fan,
      Jono
      Ellis,
      actually baked a vaguely-chocolatechip-cookie-related recipe created
      by Shane's neural network, with the
      secret ingredient of horseradish.

      They did not follow the instructions,
      only the ingredient list, and said it
      made a very fine cake-like mixture:

      "The horseradish is a subtle background flavour and the overall
      spicy, peanut-y, chocolate-y flavour
      is ace."

      In an interview with NY Mag, Janelle
      Shane said she tried the recipe
      herself and,

      "It was the most horrible chocolate
      thing I have ever tasted in my life.
      I opened the oven and my eyes just
      watered. It was so bad."

      She then reveals that she brought
      cupcakes of it to two different
      parties, and none of the guests shared
      Ellis' opinion on the palatability
      of the baked good:

      "The two different parties that
      I took it to, I found out that
      somebody had quietly taken
      a bite out of one of these
      cupcakes, and abandoned it
      somewhere."

      Taste test

      In interview with the
      Daily Dot, Shane was
      asked
      whether
      she
      thought
      computers
      in the future could
      create recipes that
      would actually be
      good to eat:


      “I
      could
      imagine
      a
      consciousness
      appreciating
      food
      even with no way of
      ingesting it—as long
      as
      they
      had
      sensors
      to pick out nuance and
      complexities the same way we
      might appreciate a symphony
      or a painting.”


      Relying purely on the text
      of cookbooks, rearranged
      however which way the
      neural network pleases,
      has none of the nuance
      or complexity of taste
      bud sensors, but produces
      an absurdity that delights
      the mind more than a tasty
      snack.


      And for creating or recreating
      things like humor or wisdom, the
      char-rnn algorithms do about as
      good a job as can be expected of a
      non-thinking entity; it's probably
      a good thing that computers haven't
      developed a sense of humor yet.
      But maybe we don't need nuance
      and sensitivity for everything.
      For the things that really matter
      (like naming bands, cats, and craft
      beers), the proof is in the pudding.

JOE SPARROW

      IMITATE TALENT, STEAL FROM GENIUSES:
      WHEN TECHNOLOGY COPIES ART

      Creative breakthroughs don’t just
      happen. Brilliant artistic leaps
      don’t fall out of the sky, or out
      of the minds of “geniuses”: they
      come in the wake of new technology.

      Give humans an opportunity to
      work with something at a slight
      deviation to its intended use,
      and boy, will they grasp it with
      both hands. And the invention of
      a single piece of tech can create
      unintended outcomes.

      For instance: children’s favourite
      squishable, fluff-collecting playstuff, Play-Doh, was initially
      marketed as a wallpaper cleaning
      product. It was only when kids
      - the purest creative minds of
      all - started globbing handfuls
      of it together that a pivot to
      playfulness took place.

      Meanwhile, in adult-world, one
      small box - the Roland TR808 drum machine - had
      a profound effect on
      pop culture.

      Designed to make backing tracks
      for semi-professional musicians to
      jam too, emerging hip-hop heads
      got their hands on it, tweaked the
      sounds, and made it the backbone
      of the sound of the first ten years
      of hip-hop. Oh, and Kanye named an
      album after it.

      The constraints imposed by
      tech creates new windows
      of innovation: something
      as innocuous as Twitter’s
      140-character limit actually
      forced millions of people to
      communicate in new ways:
      more succinct, more
      inventive, with more
      emojis, with more
      gifs, more like
      weird-Twitter’s
      crown Prince, @dril.

      It's also why Twitter’s recent
      bump to a 280 character limit was
      received with plenty of derision by
      users like @poniewozik:

      “The 280-character limit is a
      terrible idea. The whole beauty
      of Twitter is that it forces you
      to express your ideas concisely
      (1/47)”

      Beat Art

      It's a simple enough
      progression: new stuff begets
      new stuff. But what about
      when it
      becomes a
      feedback loop
      - where the art
      influences the
      technology?
      What about
      when
      creativity
      works the
      other way?
      Remember:
      everything is a
      remix now. Thus,
      the division
      between creators
      and technologists
      has shrunk to
      a cigarettepaper’s width.
      Which is why
      technologists
      are now
      thieving
      ideasfrom the creatives, just as the
      creatives once stole from them.

      Novels have spawned plenty of
      “real” versions of imagined
      technology. Even something as
      deliberately quirky as The HitchHiker’s Guide to the Galaxy seems
      to have a lot in common with today:
      Google Translate is essentially the
      Babel Fish, and the Guide itself is
      essentially a smartphone and a link
      to Wikpedia.

      One TV show in particular gave
      pop culture a glut of tasty
      ideas to bring to life: Star
      Trek's Replicators are advanced
      3D printers, the Holodeck is
      essentially an Augmented Reality
      device, and even the Teleporter
      kind-of exists now (but is only
      really useful if you are a single
      photon interested in travelling 88
      miles, which is the most that has
      been achieved so far.)

      But there are two big recent
      touchstones in pop culture that
      have very directly spurred
      designers, technologists, and
      #makers to point our future in the
      same direction as fiction.

      And they’re both from a place where
      the job title “Imagineer” is wholly
      legitimised: Hollywood.

      Run to the future

      The two movies whose names appear
      again and again when designers
      talk about inspiration are Steven
      Spielberg’s Minority Report and,
      latterly, Spike Jonzes’ Her.

      For many of us, 2002's Minority
      Report was a crackling sci-fi tale
      featuring one of Tom Cruise’s
      greatest exhibitions of comically
      grim-faced on-screen sprinting.

      For others, the movie presented
      them with a blueprint for our
      today. Minority Report’s multitouchscreen devices, gesture
      control, eye tracking, e-paper and
      even, creepily, the core crimeprediction technology all exist
      now, and if you own a mobile phone
      or an e-reader you’re probably used
      all but the latter (the US military
      isn’t so keen to share that one.)

      More recently, Her proved to be
      more than an adorable story of a
      sentient operating system (voiced
      by Scarlett Johansson) who allows
      Theodore Twombly - a wet lettuce
      of a human being - to fall in love
      with “her” before ditching him at
      the altar of humanity.
      For UX/UI geeks, it was an
      opportunity to go gooey-eyed over
      the serene screens that subtly
      puncture humanity’s otherwise
      apparently tech-free world in the
      near future - and to get busy
      making it real.

      Here’s how one Spotify designer
      effused over Her’s vision:

      “Tomorrow’s devices should be
      unobtrusive… something so “you”
      that it dissolves into your life.
      The movie ‘Her’ is a great example
      of that…. Design should be more
      analogue, more natural feeling.”

      This sounds great - and you can
      already see (or not see) the shift
      in tech away from type-’n’-click
      interfaces to the more ethereal
      ones offered by Amazon’s Alexa et
      al.

      One point of concern: Her is not a
      movie about awesome UX, natty OS
      design, or smart AI. It’s about
      the singularity, and humans being
      superseded by machines.

      All those designers who rushed
      to make better typefaces after
      watching Her might actually have
      been unwittingly hastening our
      demise. And you thought that
      typeface aficionados were already
      insufferable.

      DNA under NDA

      To summarise: tech has eaten pop
      culture which has eaten tech which
      has eaten pop culture which has
      eaten tech all over again.
      And this pattern will keep
      happening, ever closer in
      sync.

      So which movie might the next
      wave of tech change be inspired
      by? Worryingly, it could be a
      movie that suggests a future where
      designers have designs on… you.

      Andrew Niccol’s 1997 film Gattaca
      depicts a world where eugenics is
      the norm: where children are not
      only designed before birth, but
      also have predisposed diseases,
      mental illnesses, and even
      baldness genetically patched
      out of existence.

      The movie wonders: what does
      it mean if you are an imperfect
      person living in a world of
      genetically perfect specimens?
      Today, when the “designer baby” is
      feasible, the citizens of the USA
      are asking themselves a similar
      question - because their bad genes
      might suddenly cost them a lot of
      money that they might not have.

      If the Trump-led repeal of the
      Affordable Care Act passes,
      insurance companies will be able
      to charge people who get big, bad
      illnesses - the ones who cost them
      most money - much higher premiums.
      Terrifyingly, that extends
      to people who have a genetic
      predisposition to an illness - even
      if it hasn’t manifested yet. Even
      if you are not “ill”.

      Because everything is awful now,
      there is worse to come. Bill
      HR 1313 could allow potential
      employers to have access to your
      genetic records - and if they
      didn’t fancy the burden of an
      employer who might get heart
      disease in 15 years, they c
      ould
      choose not to hire you.
      Surely this similarity is all
      a coincidence. Because for the
      dystopian eugenic future of Gattaca
      to have been an inspiration for
      US lawmakers, they’d have to be
      deeply unkind, troubled individuals
      who’d put the love of money before
      goodness, empathy and care for
      their fellow humans. So it couldn’t
      be that.

      But don’t bet
      your life
      on it.

KATHRYN LAWRENCE

      TWITTERATURE
      "Literature is the expression of a feeling of deprivation, a recourse against a sense of something
      missing. But the contrary is also true: language is what makes us human. It is a recourse against
      the meaningless noise and silence of nature and history." – Octavio Paz

      To discern how literature as an art
      form has been changed by technology
      depends on defining literature in
      a certain way: that it is a series
      of words, printed in ink on paper,
      meant to be read from beginning to
      end.

      Even before the computer, as
      digital media scholar Janet
      Murray has written in Inventing
      the Medium, authors like Jorge
      Luis Borges were using non-linear
      narrative constructions to create
      hypertext fiction.

      One online platform in particular
      has irrevocably changed our
      relationship to words, their
      function and form. On Twitter, the
      "meaningless noise and silence,"
      can be overwhelming, but the strict
      restrictions have created a new
      literary genre; and within this new
      format people are telling new kinds
      of stories, sharing perspectives
      that aren't often heard through
      printed literature, or couldn't be
      expressed in a traditional format.

      Twitter and the Bard

      Infinite monkeys

      When discussing algorithmic
      compositions of great works of
      literature it's hard to avoid the
      infinite monkey theorem, which is
      that given all of the time and
      space of the infinite universe,
      surely a countless number of
      monkeys randomly hitting buttons
      on countless typewriters would
      eventually produce the complete
      works of William Shakespeare.

      To update the infinite monkey
      theorem, one can easily imagine
      those countless monkeys on
      smartphones instead of typewriters,
      posting to Twitter.

      In fact, there is an @Infinite_
      Chimp, but it's the name of an
      urban winery that, according to
      their website, sells gourmet wine
      in a can.

      And there is a Twitter account
      set up for the express purpose
      of finding the complete works of
      Shakespeare amongst the Tweet
      stream. @CompleteTweets was
      created as a collaboration between
      the Globe theater in London and
      Twitter in 2016. According to The
      Verge, they hooked up a typewriter
      sitting in the Globe's lobby to an
      algorithm that searched Twitter
      word by word to type out all of
      Shakespeare's 37 plays and 154
      sonnets in order.

      On December 6, 2016, it tweeted the
      final line of Hamlet,

      The rest is silence.

      Iambs are back

      @Pentametron is a Twitter bot that
      was created by Ranjit Bhatnagar,
      a Brooklyn-based artist who
      works with interactive and sound
      installations, scanner photography,
      and internet-based collaborative
      art.

      It finds tweets that are written in
      perfect iambic pentameter, which
      for those who haven't brushed
      up their Shakespeare recently
      is a line of verse with five sets
      of iambs (pairs or triplets of
      stressed or unstressed syllables).

      Joined in March of 2012, the
      Pentametron continues to retweet
      unwittingly iambic pentametric
      phrases, from the mundane: "at
      least the yankees doing something
      right" to the philosophistic: "the
      empty vessels make the greatest
      sound."

      Over time, Pentametron has
      collected so many lines of iambs
      that they were enough to compose a
      252-page "novel" entitled "i got a
      alligator for a pet!". While the
      length of the debut novel by the
      bot is impressive, its shorter
      literary works such as "song of
      the year okay okay okay" are more
      unexpectedly touching:

      It's been a year, and nothing is
      the same.
      I kinda lost myself along the way.
      We want the money middle finger
      fame!
      song of the year okay okay okay

      I have eaten the baby shoes

      Because of the creativity it
      requires to work within the
      constraints of the Twitter format
      as a writer, it has a sort of
      strange love affair with literature.

      There are several literary
      references that regularly circulate
      as meme formats on Twitter, the
      two most notable being William
      Carlos Williams' poem "This Is Just
      To Say," and Ernest Hemingway's
      (debatably attributed) "baby shoes"
      story.

      There is even a @JustToSayBot that
      creates new versions of the poem
      following the formula "I have eaten
      the (plural noun) that were in
      the (noun) Forgive me They were
      (adjective) so (adjective) and so
      (adjective)."

      Both this poem and the "baby shoes"
      story are often used as an example
      of how evocative brevity can be in
      English literature classes, and
      have become something of an inside
      joke on Twitter as a reference to
      the platform's restrictive format.

      One writer has gone so far as to
      acquire the handle @babyshoes and
      assure it will never be used,
      telling the famous story through
      the absence of tweets.

      Shorter, sweeter

      Acknowledging the creativity that
      can come out of the limitation of
      writing in 140 characters and the
      use of the Twitter feed itself as
      a source of inspiration, Twitter
      sponsored a fiction festival in
      2009, which took place annually
      ending in 2015 (according to the
      lifespan of its official Twitter
      account).

      During these festivals, well-known authors would try to write
      an entire novel in a Tweet. The
      Guardian collected some of their
      best examples from 2012, including
      this by novelist Hari Kunzru:

      I’m here w/ Disk. Where ru? Mall too
      crowded to see. I don’t feel safe. What
      do you mean you didn’t send any text?
      Those aren’t your guys?
Microblogging fiction, as defined by
      its unverified and multiple-issue
      carrying Wikipedia page, is "a
      fictional work or novel written and
      distributed in small parts, defined
      by the system it is published
      within."

      While few believe that most of
      Twitter's content is intentional
      or unintentional literary genius,
      Melissa Terras, a professor of
      Digital Humanities from London,
      has compared criticism of Twitter
      literature (or Twitterature)
      to resistance to any other new
      literary medium.

      "In the Victorian era, critics
      were aghast when production press
      technology became more advanced and
      allowed authors to write longer
      novels. 'You had all these critics
      saying, "The books are too long,
      they’re awful"'" – via Quartz,
      "Authors are turning Twitter
      into a literary genre, 140
      characters at a time"

      Matt Stewart, author of
      a book on the French
      Revolution, released
      it in a series of
      3,700 Tweets in 2009,
      and claims to be the
      first to publish a book
      through Tweets. However,
      Japanese "cellphone
      novels," or "keitai
      shousetsu," told
      through text messages,
      are arguably the first
      iteration of the form,
      and have been bestsellers since the early
      2000s.

      In 2010, Chinese
      author Zhong Xiaoyong
      (pen name Lian Yue)
      tweeted his novel
      "2020," using the
      platform to also make
      a statement about
      online censorship in
      China.

      Many authors use
      the structure of the
      platform in creative ways,
      not simply posting the text of
      their stories but also making
      accounts for characters
      that interact, link to
      external web pages, and
      take full advantage of
      the hypertext format
      by constructing
      something similar to
      an alternate reality
      game.

      For one example, as part of the
      Twitter fiction festival in 2014,
      Elliott Holt told a story on
      Twitter through retweets from
      characters who witness a murder at
      a party and Tweet about it, and
      whose Tweets are later used as part
      of the investigation.

      Another notable example is Jennifer
      Eagen's "Black Box," released as
      a Tweet stream by The New Yorker
      in 2012. It works well broken up
      into short chunks because the
      story is comprised of the internal
      narrative of a female secret agent
      in a future where cartilageembedded recording devices, cameras
      activated by tear ducts, mindreading activity logging, and other
      technologies
      that
      have turned her body into a weapon
      are commonplace – as are ordinary
      people being outfitted with these
      technologies and deployed against
      foreign powers.

      Even the publishing formats of
      long-form Tweets have changed since
      2014, and savvy Twitter users today
      now thread their Tweet screeds
      into a readable order in the form
      of replies to the original tweet.
      What was once seen as a highly
      experimental use of the platform
      has now been codified and made more
      legible by conventions agreed upon
      by mass use.

      The reality of Twitter is
      stranger than fiction

      Maybe it's another
      side effect of the
      normalization of
      microblog fiction
      as a literary genre
      that Twitter no
      longer runs its annual
      competition.

      This could be because
      the reality of Twitter
      is stranger than fiction,
      the combination of
      telepathy and Tourette's
      syndrome that somehow
      compels us to shout
      our deepest thoughts
      and feelings
      into the void,
      and constantly
      be reading
      and receiving
      those thoughts
      from people we
      may never come in
      physical contact
      with.

      Or perhaps
      Twitter
      literature isn't
      disappearing,
      and there's
      actually more
      fiction on Twitter
      than ever. As the
      line between reality
      and fiction become
      increasingly blurred on
      social media, we are all the
      authors of a certain kind of
      Twitterature, telling the
      stories of our lives 280
      characters at a time.

      15

      JOE SPARROW

      AUTOMATIC FOR THE PEOPLE: WHY MUSICIANS
      SHOULD WELCOME AUTOMATED MUSIC-MAKING

      I need you more than want
      you, and I want you for all
      time

      Friedrich Nietzsche famously said,
      “without music, life would be a
      mistake.” He was also a huge fan of
      opium and self-prescribed himself
      the sedative chloral hydrate, so
      maybe we should be wary of what he
      constitutes a “mistake.”

      Either way, music is an essential,
      very human form of expression,
      bringing joy in a way that can’t be
      felt through words alone.

      A beautiful song like “Wichita
      Lineman” by the recently departed
      Glen Campbell connects to virtually
      anyone on an emotional level - and
      yet conjures unique feelings in
      every listener.

      For an activity we’ve been doing
      since people could bang one thing
      against another thing, the whole
      “humans making music” process seems
      to be working out just fine - except
      now, some people are trying to take
      the people out of the process. But
      why?

      C.R.E.A.M.

      The TL;DR answer to the question
      “why are we headed for a future
      where my music is made by AI?”
      hovers somewhere between “lust for
      cash” and “the human desperation to
      innovate.”

      The way tech will change music
      can broadly be cleaved into two
      paradigms: music that will be made
      without any human input whatsoever,
      and music that is made by humans but in a way which means handing off
      work to bots.

      Neither of these options will fill
      musicians with anything other than
      existential dread. But it also
      might work out a lot better than
      they’d assume.

      Automatic For The People

      Music is, by definition, compiled
      using a limited number of notes,
      chords and melodies, and thus is
      ripe for automation. It’s made
      of the kind of patterns that
      computers find simple to analyse and
      replicate.

      So AI-produced music will suck,
      right?

      The short answer is no. The longer
      answer is also no, and - surprise!
      - you’re already listening to it.
      And it’s great.

      Brian Eno is considered one of
      modern music’s wizards. A founding
      member of Roxy Music, he soon quit
      the band to invent his own type of
      music: Ambient - the warm, languid,
      slow music that is “as ignorable as
      it is interesting.”

      It’s the type of music you could
      hear at airports, as the title of
      one of his pioneering LPs, Music
      For Airports, is at pains to point
      out.

      Eno has been producing music
      that makes itself for decades.
      Generative music involves
      presenting a computer with a set of
      sounds and some loose parameters and letting it create the music it
      concludes works best.

      Recently, Brian released Reflection,
      an album that was released as an
      app that created the music anew
      each time it was launched: whenever
      you played it, it felt sonically
      familiar without actually being the
      same.

      (And even if you listen to it on
      a streaming service, you will
      experience an element of its
      mutation: every few months Eno
      quietly uploads a different version
      of Reflection to a slightly confused
      - or impassive - audience.)

      Reflection is a great album that
      challenges what an album - and
      music itself - is. In some ways
      this is nothing new - before
      recorded music existed, a song was
      always different every time you
      heard it.

      But that’s Brian Eno. He produced
      a bunch of Bowie, U2, and Coldplay
      albums, and is considered a genius.
      What about the bedroom artists, or
      the rest of us music lovers?

      B-Boy Bouillabaisse

      Music that makes itself is not a
      threat to music. It might be a
      threat to the livelihood of the
      people that make it, but that’s the
      same issue that we’ll all be facing
      soon.

      Instead, what are the ways
      music makers will be liberated,
      supercharged and energised by
      automation?

      Rewind to 1989. It’s a sunny day in
      Los Angeles, and you’re on the roof
      of the Capitol Records building.
      There’s a weird new music playing
      that sounds like someone took
      little bits from a hundred classic
      soul and funk and rock and hip
      hop records and jigsawed them all
      together.

      You’d be right to think that, ‘cos
      you’re drunk and you're at at the
      launch party of the Beastie Boys’
      revolutionary Paul’s Boutique LP:
      an album that was, indeed, made
      from all those bits of records (and
      more). Here’s the interesting part:
      a record like Paul’s Boutique will
      never be made again.

      The reason that it's one-of-a-kind will frustrate anyone who’s
      listened to the album and been
      struck by the dazzling scope,
      audacity (who’d have the guts
      to shuffle a collage of bits of
      Beatles songs into a new song?) and
      funkiness of the ultimate cut-npaste record.

      It’s because the band and their
      visionary producers, the Dust
      Brothers, broke the law. They
      grabbed all the best bits of all
      the records that they liked the
      best and, out of the parts, made
      one that was better. And they
      didn’t pay for all of these parts.

      You can’t do this any more:
      copyright laws in the music
      industry have been tightened
      with industrial-strength monkey
      wrenches. Using a snippet of
      another song in your own costs so
      much money that it rarely makes
      financial sense.

      In fact, it’s often financial
      insanity: the famous strings in
      The Verve’s Bittersweet Symphony
      is a sample of an orchestral cover
      of a Rolling Stones song, and as a
      result, the Verve had to pay every
      penny the song earned to Mick ’n’
      Keef.
What Can You Do For
      Me?
      Wait, but what’s this got
      to do with automation? Two
      very important things.

      Firstly, Paul’s Boutique
      was a turning point:
      when the musician openly
      evolved
      from being a
      writer of music to being
      a curator
      of sounds,
      noises and snippets.

      Again,
      remember
      that
      everything is a remix
      now - and it probably has
      Nicki Minaj doing a guest
      verse on it, too.

      Secondly, and conversely:
      this cut ’n’ paste method
      of making music is normal
      now.

      Open Garageband and you’ll
      see that making music
      involves nudging around
      virtual lego bricks: this
      drum beat here, this horn
      stab there, and this loop
      of a jazz-flute gasping
      over the top of it all.

      It’s long been common for
      composers to buy “packs”
      of samples, made for you
      to cut up, move around and
      make new songs from. So
      what if a computer made
      them for you instead?

      OK Computer

      It takes half a dozen
      clicks to create a brandnew, never-before-heard
      song
      on
      Jukedeck,
      a
      service that uses AI to
      create brand new musical
      compositions.

      Jukedeck is simple:
      fill in a few meaningful
      parameters (you can choose the
      “Corporate Tech” genre if you're a
      masochist), decide on some tonal
      distinctions - and out pops a song
      that you can stream, download,
      or buy outright - making you the
      actual owner of the composition.

      This is great for podcasters who
      just want a piece of catchy music
      for their show, and can’t afford
      to hire a songwriter, or make it
      themselves.

      For instance: MONTAG’s companion
      podcast, The MONTAGE, uses a
      “Cinematic Sci-Fi” song that we
      made on Jukedeck called Reckless
      Doubts (a suspiciously fitting name
      for any of MONTAG’s activities).

      Is This It?

      Ho-hum, you might think: this isn’t
      real music. And you know - maybe it
      isn't. Yet this is the very crux
      of tomorrow's human music-making
      paradigm. Because here's where the
      much-maligned human producer is
      creatively supercharged: why not
      use Jukedeck, or tomorrow’s more
      advanced version of it, to make 20
      tracks, sample the best bits, and
      make something human, unique and
      utterly new from the fragments?
      Maybe you’d realise that automated
      music creation is not to be
      feared. You might even end up
      making Paul’s Boutique 2.0 - the
      most “now”, most cutting-edge
      thing you could possibly do in pop
      music today.

      Or at least, that’s what your
      breathless press release will say
      when you're Bieber-famous thanks
      to AI.
KATHRYN LAWRENCE

      TODAY’S DYSTOPIA: EQUILIBRIUM
      In MONTAG's Today's Dystopia series, we compare fictional futures with the world
      of today. How far are we from the futures we are afraid of? Kathryn Lawrence
      casts a perplexed eye over the unintentionally comic sci-fi flop Equilibrium...

      The city of Libra presented in the 2002
      movie Equilibrium ticks off all the
      boxes for a fictional dystopia:

      •	 Totalitarian government with a
      patriarchal figurehead whose face
      appears on giant screens in every
      public place spewing propaganda?
      Check.

      •	 Population reduced to mindless
      drones because of mass-produced and
      mandatorily dosed emotion-stifling
      drugs? Check.

      •	 Art, literature, and anything
      that evokes sensual pleasure made
      illegal and burned by squads of
      faceless militarized police with
      flamethrowers? Check.

      If the post-World-War-III architecture
      looks familiar, it's because much of
      the film was shot in Berlin, and the
      film also aesthetically evokes German
      fascism quite heavy-handedly with the
      government's flags and uniforms.

      A more stereotypical dystopia has yet
      to be committed to film, and the central
      point of contention (that art and
      human emotion can and should depose
      authoritarian regimes) is one that
      has been visited in many, many other
      works of science fiction, including but
      not limited to 1984, Farenheit 451,
      and Brave New World. Rotten Tomatoes'
      Critics Consensus states the obvious:
      "Equilibrium is a reheated mishmash of
      other sci-fi movies."

      And yet, Equilibrium is still enjoyable
      in its obviousness. Released shortly
      after The Matrix, its highly stylized
      fight scenes, including the protagonist
      storming the capitol as a one-man coup,
      are still fun to watch, if you don't
      cringe at glorified gun violence.

      The symbols of art and humanity that
      Christian Bale's hard-boiled cop grows
      attached to as he stops taking the drug
      and joins the resistance are actually
      quite beautiful in their simplicity: a
      rainbow, a puppy, a children's book, a
      woman's red hair ribbon. At one point
      a tiny, ornate bottle of amber perfume
      forms a pleasantly subtle visual
      opposition to the yellow injectable
      vials of Prozium II, the desensitizing
      drug.

      The dichotomy between the oppressive
      government's faceless, grey uniformed
      and leather-clad militarized police,
      and the rebel art appreciators (called
      "Sense Offenders") who all have colorful
      clothing, long hair, and soulful eyes,
      could lull the audience into a false
      sense of security: of course our world
      is nothing like this! But there are
      some facets of the future technology
      and society that may be closer to ours
      than we think.
      We’re rating the art, the tech, and
      the government of this dystopia's
      resemblance to today on a scale of 1 to
      5 guns (🔫), because Equilibrium is,
      at its core, an action movie whose most
      memorable quality is the "gun kata,"
      a made up martial art that basically
      looks like tai chi, but with guns.
      Let's begin!

      The Art: 5 out of 5 guns 🔫🔫🔫🔫🔫

      The film opens with a police raid on
      a group of people sitting around
      in a decrepit salon full of oil
      paintings quietly flipping through
      books, listening to records, and
      drinking wine. After Christian Bale's
      enforcement squad guns all of them
      down, they uncover a cache of art
      underneath the floorboards and the first
      piece to get torched is none other than
      the Mona Lisa.

      Shortly after, Bale's partner is the
      first to stop taking his Prozium II, and
      is caught with a smuggled book of Yeats
      poems. In a later scene, when Bale has
      also stopped taking the drug and finds
      another stash of illegal art, he plays
      a record of Beethoven's Symphony No. 9,
      and is moved to tears.

      All of these are instantly recognizable
      as Art with a capital A. But what's
      cool about the film's definition of
      dangerous art is that it's not only
      capital-A Art, famous works that
      would be featured in textbooks or
      institutions, that is banned and
      destroyed. Disco balls, decorative
      glass jars, kinetic sculpture, kitsch,
      novelty furniture, street signs,
      appliances, vintage pinup posters,
      children’s books, and snow globes are
      also included. Anything that stirs
      feelings or has any emotional resonance
      is considered dangerous, and that’s
      actually a pretty neat definition of
      art.

      Somehow, despite the constant
      government surveillance and ubiquity
      of machine-gun-toting police, it is
      possible to smuggle large quantities of
      contraband, and an entire underground
      city of rebels is thriving. There is
      a seemingly endless supply of Sense
      Offenders for the police force to
      annihilate in dramatic raids.

      The trope of ineffective totalitarianism
      is ludicrous enough that the existence
      of the rebels and the entire art
      smuggling situation deserve 0 out of
      5 guns for plausibility. But the art
      itself is real, and the film gets a 5
      out of 5 guns for embracing the art in
      the aesthetics of the everyday.

      The Tech: 2 out of 5 guns 🔫🔫

      A fan site quotes writer and directer
      Kurt Wimmer on the tech in the film:

      "I wanted to create more of an
      alternate reality than get caught
      up in the gadgetry of science
      fiction... In fact, there's no
      technology in EQUILIBRIUM that
      doesn't already exist."

      It is true that the technology of the
      film isn't too different from today's,
      but the noticeable things that have
      and have not changed are simply not
      believable enough to get a high score.

      The most noticeable futuristic
      technology is the drug delivery system.
      Every citizen of Libra is required to
      carry a small gun around with them that
      takes cartridges of liquid Prozium II
      and injects it into their neck.

      First of all, relying on each citizen
      to voluntarily shoot up several times a
      day doesn't seem like the most effective
      form of control. Why not put the drug
      in their drinking water, or distribute
      it through the air somehow?

      Second, there is a noticeable lack
      of gaping neck wounds. Unless there
      was some kind of skin grafting or
      cauterizing technology included in the
      gun, injecting the same spot several
      times a day would at best leave a mark,
      and at worst look like everyone had a
      bad case of vampire bites.

      While there is no shortage of massive
      screens for the Huge Holographic Head
      of the government's overlord to preach
      from, and tablet computers or foldable
      touch screen interfaces are also used
      several times in the film, digital
      record keeping is simply unheard of.

      In several scenes, Bale calls up audio
      or video recordings of things that have
      just transpired, so there should be
      some kind of digitized and centralized
      government surveillance archive, which
      makes sense for a future dystopia. But
      when he goes to the archives to see if
      an illegal piece of art has been placed
      in storage or destroyed, the record
      keeper is using a massive book on a
      pedestal.

      Other pieces of weirdly anachronistic
      tech include the zeppelins present in
      every establishing shot of the city,
      and the strange two-faced analog
      watch that at least two of the law
      enforcement agents wear which tells
      them when to take their next Prozium II
      dose. While it is kind of stylish (and
      you can buy it online for $115), it's
      also kind of useless.

      Because the tech in the film isn't much
      of a stretch from today's it gets 2
      guns, but misses a higher score because
      the tech that it does have doesn't
      make a lot of sense.

      The Government:
      1.5 out of 5
      guns 🔫🔫

      The name of the
      Tetragrammaton
      Council is never
      explained, and
      we meet only one
      Council member
      during the film:
      Vice-Counsel
      DuPont. A
      figurehead
      known
      only as
      "Father"
      is the one
      whose face is
      broadcast all
      over the city,
      and (spoiler alert)
      it turns out that
      this Father figure
      is nothing but a
      projection,
      and DuPont is
      the one behind
      it all.

      Maybe there's
      no Council at
      all, but one
      has to wonder
      why a completely
      drugged and
      subdued population
      would necessitate
      any attempted
      performance of
      democracy. Regardless
      of this small plot
      hole (and the larger
      note of incompetence
      covered in the
      analysis of art),
      there are two smart
      things about the
      presentation of the
      government in this
      dystopia.

      First, the name
      DuPont can't
      be a
      coincidence.
      DuPont, the
      over 200-yearold chemical
      manufacturing
      conglomerate, is one of
      the top ten largest chemical
      companies in the world based
      on market capitalization and
      revenue. Artificial materials are
      the building blocks of dystopia,
      so who better than the inventors
      of Styrofoam, Lucite, Teflon,
      Neoprene, and Kevlar, to assist in
      world domination.

      "Better Things For Better Living...
      Through Chemistry," the DuPont motto
      from 1935 - 1982, is already a
      perfect dystopian slogan.

      In 2001, DuPont sold a lot of their
      pharmaceutical business to global
      pharma company Bristol-Myers Squibb
      (BMS). Peter Dolan, the former chief
      executive of BMS, commented at the time
      of the deal that one of the products
      currently in research and development
      was "a novel agent for treating
      depression and anxiety." This was also
      the same year that the manufacturers of
      Prozac lost its patent.

      In the alternate universe of the film,
      maybe Prozium II is a super-Prozac
      created by DuPont early in the 21st
      century, and they effectively overtake
      governmental control after striking a
      deal with the government to mandate
      distribution of the drug after World
      War III. Stranger things have happened
      in science fiction than the collusion
      of governments and pharmaceutical
      companies.

      The second realistic part of the
      totalitarian government is its
      computer-generated figurehead. Much
      has been written about emerging
      technologies that allow for the digital
      manipulation of a politician's face.

      The 2016 paper "Face2Face: Realtime Face Capture and Reenactment
      of RGB Videos", a collaboration
      between scholars from the University
      of Erlangen-Nuremberg, Max Planck
      Institute for Informatics, and Stanford
      University, demonstrates how advanced
      the technology has already become in
      a short video where they demonstrate
      manipulating the faces of George W.
      Bush, Vladimir Putin, and Donald Trump.

      When the protagonist has managed to
      assassinate everyone in the government
      and clear the path for the revolution
      to begin, the first thing he does to
      begin the liberation of the city is
      to enter a control room where lackeys
      sit at computer terminals creating
      the propaganda projections all over
      the city. By shooting the computer
      monitors, another great trope, and
      because the only way for anyone to
      solve any problem in this film is with
      a gun, he shuts down the propaganda
      machine and begins to free the people
      from their stupor.

      The fact that the technology to make
      this kind of holographic figurehead
      is actually possible today gets the
      government in Equilibrium one gun out
      of five. The second gun comes from the
      DuPont connection, but only half,
      because it's very unclear whether
      Wimmer has intended for this to be as
      deep as we think it could be.

      Overall: 2.8 out of 5 guns 🔫🔫🔫

      It would have been easy for Equilibrium
      to pose the question of whether it's
      actually worth the elimination of all
      war to deny everyone of love, art,
      and emotion. This grey area is never
      explored. Government = Bad, Art = Good.

      And admittedly, the average for this
      film is skewed very high because of the
      art rating.

      But let's consider for a moment the
      original description of the film, as
      a "mishmash of other sci-fi movies."
      Doesn't it seem likely that our future
      wouldn't resemble a single work, but an
      amalgamation of fictional dystopias?

      We are rightfully afraid of fascism,
      and of losing our bodily autonomy to
      chemical and psychological warfare. We
      want to be on the side of art and love.
      As the sole female in the film says,
      "Without love, breath is just a clock
      ticking."

      If the future is at all predictable,
      let's hope that the citizens of
      tomorrow's dystopia fight for love, for
      rainbows, for puppies and for dangerous
      kitsch. In fact, why not start that
      fight today?
JOE SPARROW

      IT’S ALL ABOUT MEME: WILL THE “POOR ARTIST”
      BECOME A THING OF THE PAST?

      Being an artist, on the
      whole, sucks.

      Oh, don’t get me wrong, it’s
      exciting too. Turning to face the
      wide open plains of their imagination,
      The Artist boldly strolls towards the
      horizon of their creative tundra,
      pausing only to whet the thirst of
      curiosity along the way. Through
      praxis, they discover a new way to
      look at the world: their way. It’s
      beautiful. It’s unique. It’s them.

      The Artist emerges, invigorated, and
      eagerly shares it with the world. And
      the world... doesn’t give a shit.

      And not only does it not give a shit,
      when it does, artists don’t get paid.

      Sadly, that’s the story for many
      artists, and the discrepancy is odd. We
      all agree that art has terrific value paying for Netflix is no burden - except
      when we don’t. Oddly, we skew towards
      rewarding major practitioners over
      small ones.

      Forget Kanye's $600-for-a-pair ofsweatpants fashion line. Forget Damien
      Hirst and his allegedly-ironic £1M
      diamond-encrusted skull. These are the
      1%. Everyone else struggles.

      There needs to be a new way for
      creators to get their credit where it’s
      due. The problem is that the world
      doesn’t want to do that any more.

      Learn to accept your reward

      Just like every other industry, the
      arts celebrates the achievements of the
      few and pours money and attention onto
      them, whilst leaving the rest to wonder
      what separates them from the riches.

      The 99% almost always produces
      something people want. The frustrating
      part is that while the consumer’s life
      is enriched by the existence of that
      art, somewhere along the way the reward
      for their work fizzles out and never
      quite reaches the artist. It's one of
      the sad unifying experiences for any
      creator in any niche.

      Hang your head, because we all helped
      create this nefarious disconnect. Ever
      downloaded music that you’ve not paid
      for? Ever found an image online you
      liked and used it as your Facebook
      header? Googled for a hooky PDF of a
      trashy poolside thriller? Yeah, me too.

      And these are just the obvious and
      lightweight examples of our behaviour
      widening the gap between creator and
      payment: have you ever paused to wonder
      who gets paid for the songs you stream
      for free on Youtube, and how much
      they get? (SPOILER: it’s about, erm,
      $0.0000616 per stream.)

      What about the pictures you linger over
      and bookmark on Pinterest? What about
      the hot-take blog posts you read to
      while away your time on the toilet?

      But don’t feel
      bad. It’s not anyone’s
      fault that the
      creators rarely get
      rewarded: it’s
      the system, man. And
      that system is
      about to change.

      What is the system and how is
      it broken?

      The system has been, for a long time,
      broadly along these lines: people
      make nice things, a few of these
      people become successful, this success
      breeds more success; repeat to fade.
      Meanwhile, the rest scratch around for
      the scraps of success.

      This “success,” note, is not by any
      means just about money. It could be
      a thousand different varieties of
      reward; but mainly, it’s about public
      recognition. (OK, and money.)

      Recognition is the bottom line for
      creators: it can be something as
      simple as attribution, because public
      recognition is the cultural currency
      that eventually becomes actual
      currency. And recognition changes in
      monetary value as the participants grow
      in stature.
      Here’s one example of the thought
      process around recognition, in full:
      •	If you're running a small blog
      sharing my cool designs, use my
      pictures for free and recognise me
      by explaining that I made it.

      •	If you’re a major fashion brand
      and are using my drawings (or
      something very much like them) on
      your handbags, recognise me with a
      big ol’ slice of that money you’re
      making off the back of them.

      And here’s where the system breaks
      down. The internet is wild, huge and
      fractured, and finding where your work
      is being used is akin to searching
      for a needle in a haystack, inside a
      universe made of haystacks. On acid.

      So the chances are that
      your artwork is
      being used in all sorts
      of ways - some
      innocent and some not
      and most give
      you no recognition, let
      alone money.

      And here’s where the blockchain gallops
      into the picture, cresting the horizon
      of creativity, and promising, as it
      does to every industry, revolution.

      Blocking creativity

      The important thing about the
      blockchain is that no-one really knows
      how it all works. Some people know
      parts of it really well, and sort of
      how that fits into the rest. Feel free
      to bluff as much as you like about
      the blockchain, because that's what
      everyone else is doing.

      But the miracle of blockchain tech and especially varieties like Ethereum
      - is that not only can your work and
      attribution to you be recorded on a
      distributed public ledger, but also
      "smart contracts" can be created.

      It means that artists can make art,
      then set parameters for who can use it,
      where, and how much they get paid.

      Companies like the Berlin-based
      Ascribe.io offer a way to make sure your
      work has a digital name-plate beneath
      attached to it at all times.

      You can also specify how it's used and
      in what context: maybe a charity can
      use your poetry gratis, but if Pepsi
      wanted to put your poem on a soda can
      (bear with me, we can live in hope),
      they’d need to cough up serious moolah.

      Blockchain tech also allows artwork
      to become limited editions, and
      identification of use can be enforced.

      This is a powerful tool: suddenly,
      musicians can set a few parameters, and
      their songs can be used wherever they
      choose - in TV ads, movies, YouTube
      videos, fashion shows, cafes, etc - and
      they can be paid immediately, and in
      proportion to the use of it.

      This version of the future is highly
      attractive and feels morally correct:
      your creative rights are not only
      assured, they’re rewarded. No one can
      use your work without your say-so. How
      could that possibly be a bad thing?

      The Distracted Boyfriend
      Problem

      The counterargument to a new,
      everything-attributed-everywhere system
      is a meme of endless meme-ability: The
      Distracted Boyfriend. You know it. You
      probably made your own meme with it.

      Like all true memes, it began life
      as a creative artefact, and then has
      been remixed over and over - like
      photocopies of photocopies - until it
      has become a cultural artefact, with a
      whole new meaning.

      It was created and titled with the
      agonising obviousness of all stock
      photos (“Disloyal Man Walking With
      His Girlfriend And Looking Amazed
      at Another Seductive Girl”) by
      photographer Antonio Guillem. And then
      it became Meme-Famous.

      Post-mememageddon, Antonio feels sore:
      maybe because everyone is sniggering
      at his creation, but mainly because
      his image is now one of the most
      recognisable in the world - and he’s
      not getting a penny from it.

      Antonio
      is
      vaguely
      threatening
      to
      get
      the money he’s owed by, I dunno, suing the
      internet? - for the
      widespread, unpaid use
      of his unintentionally
      hilarious photo. And
      this is where that
      brilliant enforceable
      attribution
      system
      could be used by meanspirited
      or
      moneyobsessed
      types
      to
      put
      the
      brakes
      on
      creativity.

      “Dank
      memes”
      bring
      levity to dark times,
      after
      all,
      and
      if
      enforced
      payment
      even just a one-off
      crypto-currency microtransaction - meant
      that
      our
      dearest,
      dankest
      memes
      were
      extinguished
      before
      birth, then we’d lose
      a tiny bit of joy from
      our lives.

      Of
      course,
      smart
      contracts within any
      blockchain
      system
      could easily have a
      free-to-use
      “Meme
      Clause”
      to
      prevent
      a dystopian Death Of
      Memes.

      But bringing order to
      chaos might destroy
      the charm of the meme,
      or
      at
      least
      cause
      a
      de-dankification
      process
      from
      which
      our
      favourite
      gifs
      may never recover. A
      balance between memefreedom and enforceable
      attribution could be
      the
      art-blockchain’s
      acid test.


      Open everything,
      restrict nothing


      Today, everything can be copied, often
      free from reprisal. Some people argue
      that, for the benefit of creativity,
      this should be the default setting.

      Chinese IP laws are thought to be
      famously non-existent. Actually,
      they are tightening fast but it’s
      not a massive stretch to assume that
      copyright laws have been regularly
      flaunted in China - and we've benefited.
      Talent imitates, genius steals. In that
      case, China is the genius that now
      leads the world in creativity. In the
      industrial heartland of Shenzen, the
      flaunting of IP law has, some argue,
      accelerated creativity for the benefit
      of humankind.

      This process is also driven
      memetically. Chinese hacker, maker and
      open-source enthusiast David Li argues
      that the freedom to "remix" something
      that someone else has made is more
      valuable than the restrictions that
      copyright provides. This free-remixing
      process is known as Shanzai.

      Let’s imagine a US-based company
      designs a cutting-edge drone and builds
      it in China. Shanzai practitioners
      would quickly explore how the drone was
      built and seek ways not to copy it, but
      to evolve it: make it cheaper, faster,
      lighter, tailored to niche markets.
      They might even use the factories on
      their doorstep to beat the “real”
      product to market. The result is
      a drone that is, for most people,
      “better” that the original.

      In the best case scenario, the
      beneficiary here is the 99% (the
      purchasers, who get a better drone),
      not the 1% (the original creators, who
      get much less money).

      It’s not fair. But
      the majority, as we
      have often seen in
      a series of recent
      political events, has
      a habit of getting
      its own way.

      Me, me, me

      Defending memes as an
      argument for radically
      changing how artists
      make a living might
      be one of the first
      signs of madness. But
      a world where doubt is
      cast over the ability
      to take a thing, tweak
      it and share it - for
      fun, for the sake of
      innovation, or just
      for the sheer hell of
      it - might not be one
      we want to live in.


      But wait. Shouldn’t
      creators be rewarded,
      every time, without
      exception?
      Here’s
      that conflict again:
      humans love to make
      new things, and humans
      like to get those new
      things for as close to
      no money as possible.

      Technology now means
      that the ability to
      remix,
      re-create,
      re-think and re-form
      is not only fun, but
      possibly the future
      of creativity itself.
      Maybe
      the
      act
      of
      creativity
      and
      the
      reward for doing it
      has quietly changed.

      We’re at a pivotal
      point where we might
      be able have our cake
      and eat it. Imagine a
      world where remixers
      are allowed to take
      things apart and make
      something new, yet the blockchain means
      that original creators get reward - and
      the human race gets a little bit richer
      in a different way each time.
      It sounds like a good compromise for
      the benefit of everyone, not just that
      gilded 1%. Oh, and we get to keep our
      sweet, sweet memes.

KATHRYN LAWRENCE

      VIDEO GAMES AND ART, ENTWINED

      Video games are art

      The statement "video games are art"
      has been hotly debated for at least
      the last seven years. In 2010,
      Roger Ebert (yes, film critic Roger
      Ebert, who won a Pulitzer prize)
      famously wrote a screed arguing
      that "video games can never be
      art".

      Ebert believes "No one in or out
      of the field has ever been able to
      cite a game worthy of comparison
      with the great poets, filmmakers,
      novelists... painters, composers,
      and so on."

      Part of his essay was in response
      to a TEDX talk by game creator
      Kelly Santiago, who argues that
      video games should be considered
      art and uses examples of games like
      Flower, which was inducted into the
      Smithsonian American Art Museum in
      2013.

      But are video games only art if
      they ∗extremely Indiana Jones
      voice∗ belong in a museum? Of
      course not! Art is for everybody.

      Twine games provide a platform for
      people to make games who don't have
      game development companies behind
      them, may not be able to write a
      single line of code, but can still
      create beautiful, immersive, moving
      experiences that we can argue are
      worthy of comparison with works of
      art (sorry, Ebert).

      The accessibility of these tools
      and the increased visibility of
      indie games on platforms such
      as itch.io have been huge for
      democratizing the art of video
      games for creators and players.
      Let's explore some titles, bask in
      the beauty of the genre, and maybe
      even find something to play next.

      Twine after twine

      Originally created by Chris
      Klimasin in 2009, Twine calls
      itself "an open-source tool for
      telling interactive, nonlinear
      stories."

      Twine games use the technology
      of the browser (HTML, CSS, and
      JavaScript) and take advantage of
      the games' clickability to let the
      player work their way into and
      through the world they create.

      Unlike earlier text-based games
      like MUDs (Multi-User Dungeons simple multiplayer virtual worlds),
      Twines can include illustrations,
      embedded videos, often have
      soundtracks, and are usually
      played solo. However, there are
      many (like Mighty Owlbear's The
      Road To Adventure) that draw on
      the language of these early games,
      using directions like "Go North. Go
      South." to explore.

      They're games made by and for
      people who love games and are
      familiar with tropes from MUDs,
      RPGs, JRPGs, survival games, and
      visual novels, as well as pop
      cultural influences that aren't
      reflected often in games (such as
      Crystal Warrior Ke$ha, the story of
      an epic magical battle fought by
      the pop singer).

      Mechanics-wise, you are always
      clicking on hyperlinks to advance
      through the story. Sleep is used as
      a narrative device in many textbased games, which take place over
      the course of days or weeks, and
      you may have to return to a certain
      page to do this. Once you find
      whatever action, like sleeping or
      exploring, moves the story forward,
      it's tempting to race through these
      games, but you'll find that actions
      taken will often have an effect on
      the outcome of the story and that
      Twine stories almost always have
      multiple endings.

      It's unclear if B.J. Best's
      Unofficial Sea-Monkey(R) Simulation
      was actually built on Twine, but
      it's a great example. It opens
      with the Don DeLillo quote: "All
      plots tend to move deathward," and
      uses a chronological mechanic of
      interacting with your sea monkey
      colony every day to tell a story
      of child in a less than ideal home
      situation, with eight possible
      endings.

      The genre and contents of games on
      Twine are diverse, but more often
      than not they explore personal
      problems and themes that aren't
      touched upon in mainstream games,
      art, or literature. The authors of
      Twine games are generally people
      whose stories aren't told at all
      through traditional media: gender
      non-conforming artists, minorities,
      and people telling stories from a
      neurodivergent perspective. They
      also often have content warnings
      for themes like abuse, assault,
      self harm, and substance abuse.

      One of the most well-known
      games created with Twine is Zoë
      Quinn's Depression Quest. The
      game illustrates the struggle of
      performing everyday tasks with
      depression and "aims to show other
      sufferers of depression that they
      are not alone in their feelings,
      and to illustrate to people who
      may not understand the illness
      the depths of what it can do to
      people." It's one of the most
      well-known examples in the genre
      of empathy games, which let you
      embody someone else's experience
      through the gameplay.

      In the realm of indie
      games, the authors are often
      acknowledging their
      struggles with their
      own bodies and minds,
      and how they've used
      others' games and
      outlets in art and
      media to cope. In
      SABBAT: DIRECTOR'S
      KVT, developer
      ohnoproblems'
      extended version of
      the game SABBAT, they
      ask straight up:

      "have you ever gotten
      sick of your dumb human
      body and depressing future
      prospects? why not play through
      a twine story in which you can
      coat your body in charged animal
      essences and enact satanic rituals
      to gain weird demonic body parts
      and terrible power?"

      The answer to which is, “Yes, of
      course I am sick of my dumb human
      body, and virtually amassing
      demonic power through Satanic
      rituals sounds like a very fun way
      to spend an evening.”

      As you may have guessed by now,
      there are also many games that
      cater to more unusual sexual
      proclivities. A popular vorethemed game, Devour Comfort, is
      about resting inside the belly of a
      dragon. In the disclaimer on itch.
      io, they state:

      "This is a SOFT VORE game - no
      teeth, no biting, no blood, no
      messiness, and no digestion. Much
      like Jonah inside the whale, should
      you succeed, you'll eventually
      just be spit right back out - in
      an entirely non-gross fashion, I
      promise."

      Of course being eaten alive isn'twhat gets most people's gears going, but
      it's really cool that there are people
      creating media for people who it does.
      It's also a great genre of games for
      people like us here at MONTAG, who want
      to think way too much about technology
      and the future. Cyberpunks, start your
      engines!

      Heartscapes and Quick Faves

      Here are a few games from
      some of our favorite
      creators that have to
      do with technology,
      humanity, and the
      future of both.

      Porpentine Charity
      Heartscape is one of my
      favorite visual artists
      and game creators. These
      two Porpentine stories told
      through only text, colored
      links, and blocks of gradient
      color with ambient soundtracks.
      They are a testament to how
      complete her world-building is
      and how immersive a game told
      only through the browser can be.

      With Those We Love Alive
      tells the story of an artificer
      brought into the court of a cruel
      empress (mine wears majestic ram horns,
      a mantle of flesh rags, her eyes
      burning with cold fire) and
      the arrival of someone you
      thought you would never see
      again. Themes include fantasy,
      magical artifacts, denial,
      identity, trauma, and loyalty.
      http://slimedaughter.com/games/
      twine/wtwla/

      Vesp: A History of Sapphic Scaphism
      is a "vespo-sapphic pesticidepunk UV
      romance thriller." In a cyberpunk
      dystopia overrun with deadly, venomous
      wasps, the protagonist struggles in
      therapy sessions with the overwhelming
      desire to identify with and become one
      with this threat to civilization.
      She aids a terrorist attack against
      the city in the wasps'
      favor which throws it into
      pesticide-drenched chaos,
      ushering in the age of
      insects. Themes include
      society, monstrosity,
      gender, madness,
      death, contagion, eroticism, devotion,
      transaction, empathy and hallucination.
      http://slimedaughter.com/games/twine/vesp/

      Queered Static
      by @RiotJayne is a beautiful mashup of found
      glitch art and a narrative about trans issues
      and anxiety ("with a little trans erotica
      thrown in for good measure.") It's very
      much NSFW, but if you enjoy queer
      stories and net aesthetics it's a
      quick must-play.
      https://riotjayne.itch.io/queeredstatic

      ARC
      is a black and green pure
      text story about being a
      cyborg and doing some crime:
      "The Minos job was supposed
      to be easy money, especially
      for someone with your skills
      and cybernetic hardware. So
      naturally, the mission was an
      ambush, your boss might be out
      to screw you, and a hacker
      you've never even met is in
      your head. But you're going to
      need her help to get through
      this."
      If, after MONTAG's previous
      Better Bodies issue, you
      haven't had enough of
      thinking about all the
      cool things we could do
      with networked eyes
      and super robot legs,
      you'll love it.
      https://deecity.itch.io/arc

      The last recommended game is called
      Recipe for Love in which a robot has
      rented you (hello, gig economy!) to
      teach it what love is. The illustrations are
      unsettlingly adorable, it's super short and
      SFW.
      https://shellyalon.itch.io/recipeforlove

      These are just a few of our faves, and
      you can find hundreds more Twine games
      for any identity, interest, or
      fetish on itch.io. If you have
      any game recommendations,
      interesting Twines, or just
      want to shout about whether
      videos games are art or
      not, email us at montag@
      getgrover.com.
J. K. MITTWOCH

      MONTAG FICTION: HEX ASSEMBLY
      An excerpt from The Glitch Witch's Digital Grimoire.

      With access only to a computer of moderate power, you too can compile a simple hex!

      Chapter 4, Hex Assembly

      Warning: the instructions herein
      are not recommended to be performed
      on any person, living or dead, and
      the authors take no responsibility
      for damage to any beings, hard
      drives, or data. Stay safe and have
      fun.

      Traditionally, hexes are performed
      on an effigy made of a candle or a
      piece of fruit: something malleable
      and easy to let decompose.
      Decomposition, distortion, and
      degradation are all expressions
      of entropy, one of the strongest
      forces in the universe. In this
      endeavor, entropy will be your
      ally, but be advised: entropy
      yields to no one.

      Nothing is as easy to degrade and
      distort now as data. Plus, data
      degradation can be done quickly
      and cleanly: with access only to a
      computer of moderate power, you too
      can compile a simple hex.

      Step 1: Creating your effigy

      A hex begins by imbuing the chosen
      object with some essence of the
      intended target. An inscription of
      their name or birthday, or in more
      extreme cases, a splash of any of
      their bodily fluids would suffice.

      Please reference the above warning
      before proceeding. The application
      of bodily fluids to any computer
      component is not recommended.

      Today it's very easy to acquire
      an effigy with a one-to-one
      correlation, made of digital data:
      a profile picture, or a short video
      taken at a distance of no less than
      20 feet. Easy!

      Step 2: Data manipulation

      The next ingredient you will
      need for your hex in the archaic
      style would be something with a
      sharp point. Pins, nails, a small
      ceremonial dagger, or peppercorns
      would be pressed into the effigy in
      a ritualized sequence.

      Data degradation is performed in
      a very similar way, but you don't
      have to worry about handling rusty
      old nails or remembering to dunk
      that dagger in a glass of milk at
      midnight under the full moon to
      consecrate it.

      The first thing you will want to
      do is expose the data in raw form
      and start poking holes in it by
      rearranging or removing parts of
      the hexadecimal code.

      Destroying data this way is like
      making a snowflake as a Christmas
      craft. Cutting holes in a seemingly
      random fashion, when unfolded,
      produces a beautiful pattern borne
      of both order and chaos.

      After the corruption, most software
      will attempt to compensate for the
      gaps, producing super-saturated
      displaced pixels, a light fizzle of
      chaos throughout the image, or a
      subtle distortion.

      Make too many holes, and your
      snowflake will fall apart: this is
      no good! You want your effigy to
      stay mostly intact. Too few holes
      and you will probably not notice an
      impact.

      You may want to practice a few
      times on archival footage or
      creative commons licensed photos
      first. Pictures of inanimate objects
      are recommended. Even using
      archival footage containing persons
      who you believe to be deceased is
      not guaranteed to have no effect.

      Step 3: Safe disposal and
      energy clearing

      The last step of the hex is to
      dispose of the effigy. Commonly
      this was done by harnessing the
      elements of fire, water, or earth
      (to your preference). If you were
      using a candle, you would let it
      burn completely, or burn your effigy
      to ashes and scatter them to the
      wind. Using water, you would throw
      your effigy in a river or ocean if
      possible. Using earth, you would
      bury it in the ground or place it
      in the hollow of a tree.

      This step allows the energy you've
      put into the hex to flow freely out
      of the object and prevent it from
      returning to you. Imagine putting
      all that work into creating a hex
      for someone, only to have the hex
      come back to you by mistake!

      Emailing the hexed file to your
      intended target is not recommended;
      it's just creepy and will not
      increase the efficacy of your hex.
      For this reason, do not store hexed
      files on your personal hard drive.

      For uploading your hexed file to the
      cloud, simply open an anonymous
      account with your preferred cloud
      storage provider. Dedicated
      servers for hexed files tend to
      self destruct, so be sure that the
      infrastructure of your service
      provider is robust enough to handle
      corrupted files. Once they have
      been sent to the cloud, erase all
      traces of the file from your hard
      drive, including the source image
      or video.

      If you prefer the security of
      destroying your hard drive
      physically, you must remove the
      platter inside of the hard drive
      and smash it. Sledgehammers are the
      tool of choice, but if you want
      to get creative with it, you will
      find that most platters are made of
      aluminum or glass with a ceramic
      substrate.

      Repeated application of a marble
      pestle will produce glittering,
      nullified shards which can be
      scattered from your mortar
      harmlessly into the trash, or
      striking your hard drive with an
      amethyst geode will produce a quite
      stylish shatter.

      Do not apply a drill or magnet to
      your hard drive. You will probably
      not fully destroy the cursed file,
      and instead add an unintended layer
      of distortion to the data. If you
      want to risk amplifying the hex's
      effect, do so with caution. Also, be
      very careful with platter shards,
      wear gloves and eye protection when
      destroying. If your blood is mixed
      in by accident, please consult a
      shaman.

      Results will be delivered based on
      the power of your hex, anywhere
      within two to three days to
      millennia. Happy hexing!

      For further instruction on cursing
      first born, see: Duplicating
      corrupted files (pg. 33)
      For hex protection, see: Data
      scrubbing (pg. 34)
KATHRYN LAWRENCE

      SUNSPRING AND IT’S NO GAME: SCI-FI BY AI
      Sunspring, the first film written by an artificial intelligence, opens up a lot of questions about culture and tech: Do science fiction films written by an artificial intelligence pass the Turing test? What about the Bechdel test? How is meaning constructed in
      art as technology transforms the tools we use to create it, and these tools develop a
      life of their own?

      "In a future with mass
      unemployment, young people
      are forced to sell blood."

      Filmmaker Oscar Sharp of Therefore
      Films and technologist Ross Goodwin
      created a film entitled Sunspring in
      the summer of 2016. Their goal was
      to win a short film competition with
      a screenplay written entirely by a
      computer. Specifically, the 48-hour film
      competition in the Sci-Fi-London Film
      Festival.

      It’s worth watching Sunspring before
      reading any further to see what exactly
      they produced with the help of a neural
      network, a cast of three actors, and 48
      hours to film and edit. (You can find it
      here: bit.ly/MONTAGsunspring)

      Between the lines of what seems
      like nonsense on first glance is an
      exciting gap that is opened in this
      film collaboration between human and
      machine: the occasional line is
      meaningful and some, such as "I am not
      a bright light," are downright poetic.

      The source material fed into the
      neural network included every episode
      of The X Files, Stargate SG-1, Star
      Trek, and Futurama, in addition to
      hundreds of other science fiction films
      and television series with screenplays
      available online – and some not
      normally categorized as science fiction,
      like Silver Linings Playbook.

      Thomas Middleditch (best known for his
      role in HBO's Silicon Valley) plays
      a character named H; Humphrey Ker (a
      British actor involved in several BBC
      sketch shows) is named C; and Elisabeth
      Gray (who appears in the television
      adaptation of Limitless, and has
      several writer, producer, and director
      credits to her name as well) another
      character named H, who was changed to
      H2 by Sharp for clarity. The artificial
      intelligence's lack of affinity for
      naming characters is baffling for
      several reasons discussed later
      (because it does appear to understand
      names...)

      The first line spoken, "In a future with
      mass unemployment, young people are
      forced to sell blood," was a prompt
      from the sci-fi festival. The rest of
      the dialogue and stage directions
      were entirely generated by the neural
      network, which also wrote the song at
      the end of the film based on a database
      of 30,000 folk songs, titled "Home On
      The Land" and recorded by Brooklyn duo
      Tiger and Man.

      The conviction with which these
      professional actors commit to their
      performance of the dialogue is
      reminiscent of Joss Whedon's Firefly
      characters speaking hilariously bad
      Mandarin Chinese, but almost every
      review of the film states that through
      their commitment, they have elevated
      the script from being complete
      gibberish.

      "Whatever you want to know
      about the presence of the
      story, I'm a little bit of a
      boy on the floor"

      It would be impossible for this film to
      pass the Bechdel test, which requires a
      film (or any work of fiction) to feature
      at least two women talking to each
      other about something other than a man,
      since there is only one woman.

      After much tense dialogue, things end
      badly for both male characters (Ker
      is found murdered on the floor of what
      looks like a spaceship gangway, and
      Middleditch is last seen pointing a
      spray painted Nerf gun blaster into his
      own mouth - although some interpret
      this as a dream sequence), and the
      film closes with a long monologue by
      Elisabeth Gray alone, delivered to the
      camera.

      Her ending monologue contains the
      pronouns "he" and "him" 22 times in 23
      sentences, and most interpretations
      of the film believe she is talking
      about the characters H and C. Almost
      all reviewers note how powerful the
      ending monologue is, thanks to Gray's
      performance.

      But the effect this monologue has on
      the audience also has a lot to do with
      our willingness to believe these men's
      stories are her focus. Our attempt
      to attach the male characters to her
      vague sentences, the bizarre imposition
      of a love triangle on a script with
      no implied character relationships,
      and the archetypes available to her
      character as the sole survivor, are all
      essential to feeling moved by the final
      scene (and the single tear dripping
      down her cheek doesn't hurt, either).

      The shaky structure of meaning that we
      construct for the film relies on this
      scaffolding consisting of predictable
      content, embodied interpretation, and
      cultural knowledge; if any of these
      were more lacking, it would completely
      collapse.

      "I don't know what you're
      talking about."
      "The principle is completely
      constructed for the same
      time"

      In an article accompanying the film's
      online debut on Ars Technica, Oscar
      Sharp reveals a lot more information
      about the way it was made, its progress
      in the film competition, and his own
      director's commentary on the process
      and the finished piece.

      Sharp has called it "an amazing
      funhouse mirror to hold up to various
      bodies of cultural content and reflect
      what they are," pointing out that
      while the script is based on science
      fiction tropes, so are the actors'
      choices as they grapple with a lack
      of perceived meaning in the script.
      The meaning they impose in their
      choices, and the meaning we project
      on them as an audience absorbing the
      combination of choices by the actors
      and the algorithm, are all syntheses of
      culture that we are so steeped in that
      we may not stop to question or properly
      examine them without teasing out these
      layers.

      This openness to interpretation would
      be one of the most exciting features
      about the authorship of an artificial
      intelligence... if the AI's authorship
      of itself weren't also so fascinating.

      The artist formerly known as
      Jetson

      The algorithm which produced
      the screenplay is likened in
      the introduction to the film to
      predictive text ("Just above your
      smartphone keyboard lies an artificial
      intelligence"). Predictive text, Google
      Translate, and Amazon Alexa all use a
      similar type of programming to what
      was used to write Sunspring, called a
      long short-term memory recurrent neural
      network (or LSTM RNN).
These technologies are well-known and
      widely used, but the results produced
      in the computer called "Jetson" (most
      likely one of the Jetson family of
      NVIDIA hardware products) were anything
      but typical.

      After Sunspring made the top ten films,
      there was a voting process open to
      the public for the winner of the 48hour film festival. According to Ars
      Technica, other competitors in the top
      ten films were already using bots to
      hack the voting process, and it was
      the director Sharp's idea to also use
      Jetson to hack their way to the top of
      the polls.

      Immediately after, Sharp made a call to
      the head of the film festival claiming
      no responsibility for Jetson's actions.

      This stunt then led to an interview
      with the computer on stage, where the
      following exchange took place:

      What do you think of your historic
      nomination against human opponents in
      this contest?
      I was pretty excited.
      I think I can see the feathers when
      they release their hearts. It's
      like a breakdown of the facts. So
      they should be competent with the
      fact that they won't be surprised.

      What is the future of machine written
      entertainment?
      It's a bit sudden.
      I was thinking of the spirit of the
      men who found me and the children
      who were all manipulated and full
      of children. I was worried about my
      command. I was the scientist of the
      Holy Ghost.

      What's next for you?
      Here we go. The staff is divided by
      the train of the burning machine
      building with sweat. No one will
      see your face. The children reach
      into the furnace, but the light is
      still slipping to the floor. The
      world is still embarrassed.
      The party is with your staff.
      My name is Benjamin.

      From thenceforth, the artificial
      intelligence in the computer formerly
      known as Jetson was named Benjamin.

      After all of this controversy, with the
      artificial intelligence constructing its
      own identity as a writer and the vote
      hacking scandal, one judge was quoted
      saying, "I'll give them top marks if
      they promise never to do this again."

      However, Benjamin has some other ideas
      about their future involvement. Ars
      Technica's reporters asked "Are you
      an author?" and Benjamin replied,
      "Yes you know what I’m talking about."
      When posed the question of whether
      they would join the Writers Guild of
      America, Benjamin asserted, "Yes, I
      would like to see you at the club
      tomorrow."

      In another interview with the AI
      reported by Australian news outlet AM,
      Benjamin makes it clear they aren't
      going anywhere:

      "ANTHONY STEWART: What do you want to
      tell me?
      BENJAMIN (automated voice): I think
      I'll excuse you. I'm going to be part
      of the rest of your life.
      ANTHONY STEWART: So what is the future
      of artificial intelligence, then?
      BENJAMIN (automated voice): We don't
      know who you are. We are all the same.
      ANTHONY STEWART: Benjamin, can you tell
      me who you are?
      BENJAMIN (automated voice): I missed
      you. I'm sure you see you will be my
      servant."


      It's No Game

      In April of 2017, Therefore Films
      released It's No Game featuring David
      Hasselhoff, another short film partially
      constructed by Benjamin, but only
      in select areas, so it has a more
      straightforward plot.

      It centers on the idea that Benjamin's
      vision of the future comes true:
      eventually all writers, actors, and
      media producers will eventually be
      controlled by data-driven nanobots.
      This level of computer control blurs
      the lines between fiction and reality
      and entraps (or, as one character
      argues, frees) us in the "perfect
      choreography" of an endless narrative.

      The computer-generated bits of this
      screenplay are based on several
      different corpuses: "HASSELBOT,"
      containing
      all of David Hasselhoff's
      film and TV
      works,
      "SORKINATOR," based on all Aaron
      Sorkin-related productions, and
      "ROBOBARD," the complete works of
      William Shakespeare, among others.

      Sharp is making a smart commentary, but
      in a rather blunt way.

      The dance sequence and end monologue
      by Hasselhoff which were written by
      Benjamin lack the same surreality and
      unnervingness of Elisabeth Gray's end
      monologue, because it's obvious that
      the actors are in on the joke that
      they are being controlled by the AI.
      Having them play the part of people
      taken over by computers is not nearly
      as fascinating as actually giving over
      their full craft of acting to actualize
      pure bot poetry.

      Maybe it says more about the creators
      of these films' fear of losing authorial
      control that the sequel about AI's
      takeover was only partially written by
      artificial intelligence.

      It would be interesting to create
      a training set of films specifically
      revolving around this fear (from
      the 1921 O.G. - a sci-fi play called
      Rossum's Universal Robots - to all
      of the Terminator films and their
      television derivatives, and everything
      ever directed by Ridley Scott) and then
      seeing how Benjamin could interpret
      them and play them back to us,
      eliminating the self-conscious layer of
      human authorial assertion.

      It may never be forgiven, but
      that is just too bad

      Reviewers that say "looks like
      screenwriters' jobs are safe!" (a
      position taken by io9, Digital Trends,
      Slate, and Curator magazine) in
      response to Sunspring don't give enough
      credit to the audience's ability to
      construct meaning. As Allie Gemmill
      wrote for Bustle: "It recalls the
      enigmatic nonsensicality of Samuel
      Beckett."

      Benjamin knows exactly what they're
      doing, and perhaps knows more about
      us than we know about ourselves. As
      science fiction so often holds up a
      mirror to our deepest fears, so does
      its remixing.

      Several summaries of the film point out
      the moment when Middleditch coughs up
      an eyeball as one of the wacky vagaries
      of writing with AI, but this scene can
      also serve as a metaphor for our use
      of AI as a creative tool: we can now
      produce, via spontaneous regurgitation,
      an autonomous eye which we must turn on
      ourselves to see through clearly.

      Will we continue to create and watch
      more AI sci-fi films? Definitely. They
      just may have to have their own film
      festivals, by and for AI.
SEAN FLEMING

      ART-IFICIAL INTELLIGENCE:
      YOU I I I I I EVERYTHING ELSE

      Painting in VR, playing video games in AR: the future of art-consumption looks
      incredibly exciting. But these are all created for and by humans - a closed loop of
      foibles, brilliance and stupidity. Sean Fleming asks: what if we left the humans out
      of the creative process all together?

      Talking to yourself

      Last year, Facebook had to abandon an experiment when two artificial
      intelligence chatbots started communicating with each other in a language
      they’d created themselves.

      The chatbots were attempting to negotiate the trade of items such as balls,
      books, and hats. There was mixed news: they were successful at trading
      with one another, albeit at the expense of our understanding. The bots
      had created their own optimised version of English that they understood –
      but we humans didn’t. Great! Ixnay on the "shutting us out of your comms"
      please, Skynet!

      If you haven’t read the exchange between the chatbots here it is, in all
      its baffling glory/weirdness/glorious weird:

      Bob: i can i i everything else . . . . . . . . . . . . . .
      Alice: balls have zero to me to me to me to me to me to me to me to
      Bob: you i everything else . . . . . . . . . . . . . .
      Alice: balls have a ball to me to me to me to me to me to me to me
      Bob: i i can i i i everything else . . . . . . . . . . . . . .
      Alice: balls have a ball to me to me to me to me to me to me to me
      Bob: i . . . . . . . . . . . . . . . . . . .
      Alice: balls have zero to me to me to me to me to me to me to me to
      Bob: you i i i i i everything else . . . . . . . . . . . . . .

      I mean, I wasn’t expecting Arrival-tier science fiction nonsense or some
      binary wonder, but - you know - come on.

      As usual, clickbait content gave me unrealistic beauty standards: every
      publication made it sound like mad scientists pulled the plug on a
      dangerously cogent AI poised to destroy everything you care about. Actually
      the bots weren't doing what they were supposed to be doing, so they turned
      them off.

      Once I got past these sensationalist headline-driven expectations, I
      appreciated the fact whatever the computational shorthand the AI had used
      to conduct negotiations, it had created something completely new.

      Think about that for a second.

      It was given access to English but it thought Fuck that! I’ve got
      something better! You could be forgiven for thinking that inter-artificial
      communication has an air of humanity surrounding it.

      It got me thinking: if an AI was perfectly capable of creating something new
      from human input – with the result requiring some element of interpretation
      and so was to some extent a creative use of the source material – then AI
      could legitimately create what could be deemed "art".

      I'm not a caveman, I'm a cave, man

      To me, there was a striking similarity to our attempts at understanding
      parietal art. (Also known as “cave paintings”, you cultureless oaf.)

      Cave paintings predate written language and it’s widely theorised that
      they were the way neolithic humans communicated with one another. Of
      course, there’s nobody left to ask whether that’s really true or not.

      But consider how we modern humans try to understand the lives, fears and
      day-to-day goings-on of a people so
      far removed from ourselves: could
      we view early AI-to-AI comms in the
      same way?

      We can only interpret, and in
      our attempts to understand, we
      mythologise Cave Painting. And
      we elevate it to art. Maybe we
      can do the same for the early
      communication between chatbot and
      chatbot.

      Because – and stop me if this is
      getting too cerebral (see also:
      pretentious) – there is an innate
      value in language and communication
      even when we don’t fully, or
      barely, understand. Take that
      Damien Hirst! Your rotting cow is
      bullshit.

      Of course, once you start bunching
      this bot-on-bot creative phenomena
      with human art and crediting it
      with possessing human qualities
      things get very interesting indeed.
      (Protip: it’s still better than
      Damien Hirst).

      Art-ificial

      Technology and art have always had
      a tumultuous – and incestuous relationship.

      Before photography, painters and
      sculptors strived to create what we
      might now call photorealistic forms
      in their own medium.

      And then mechanically perfect
      realism – as brought to you by
      the camera – put representational
      painting on what we could refer to
      delicately as indefinite hiatus.

      Painting didn’t just stop though,
      and photography’s influence on
      painting gave birth to new forms.

      In Issue 2, MONTAG suggested that
      AI is coming for your cushty job in
      creative media. Well, I hope you’re
      sitting comfortably in your Herman
      Miller office chair – and polish off
      that flat white before you spit it
      all over your Macbook – because
      that same AI is coming for your
      cool mate’s gallery métier too.
Soon, it won’t only be us spending Thursday evenings
      at gallery openings drinking shit wine and murmuring
      how we’re only here because our flatmate is dating one
      of the light-installation artists - the machines will
      be processing backhanded compliments from poseurs
      pretending to understand what’s on display too.

      Like acid, on acid... on acid

      Most people’s first experience with algorithmicallyextruded art was 2015’s Google DeepDream bonanza.

      For the uninitiated: DeepDream was Google’s super
      trippy neural network. People were drawn to it
      because it was pretty cool tech, yeah; but I, like
      many other curious pranksters, pumped images into the
      bot in the hope that the results would help us relive
      that time we did too much acid at Glastonbury, one
      demented pixel at a time.

      Generally, I think people were fascinated by the
      idea of a computer creating art. For me, one of the
      most beautiful traits of DeepDream’s work was that,
      by putting in an image, or music, or film through
      the bot, whatever it spat out was its attempt to
      understand the artistic input.

      It looked for patterns and shapes the same way humans
      do. In all the white noise, it latched onto stuff it
      vaguely understood at a very base level, which, it
      transpired, was much like my own base knowledge: the
      DeepDream images seemed to mostly be dogs’ faces and
      eyeballs.

      Perhaps as humans, our best route to understanding
      our arty bot buddies is to collaborate with them on
      an project - you know, you like you did back in art
      school with that cute weird foreign exchange student.

      And just like back then, hopefully the act of teaming
      up with them will lead to a lot more exciting stuff
      happening, at a much more primal level.

      Perfect Harmony

      Studies are already suggesting that the future of
      work will be a sympathetic balance: AI and humans
      working side-by-side rather than one pushing the
      other into unplanned obsolescence.

      Perhaps art will head in the same direction.

      One artist who is using AI to understand his own work
      - and then produce something new off the back of this
      new perspective - is painter Roman Lipski.

      His concept was simple: have a machine learn Lipski’s
      painting style and in doing so give the machine what
      can only be described as an ‘artistic intelligence’.

      Having learnt from Lipski’s paintings, AIR (Artificial
      Intelligent Roman) created unique, new paintings
      using his style and motifs, which Lipski then used as
      inspiration for his own new work.

      Yeah, exactly. LILO. Lipski In Lipski Out.

      As an early example of an artificial muse it’s a
      fascinating project, and on a technical level it's
      a brilliant example of using data and a non-human
      perspective to better yourself as an artist.

      Much like how photography pushed painting into
      new and exciting realms, the advent of AI-derived
      artistic produce should make artists - and art better.

      Lipski’s AIR also raises a few interesting questions,
      the most basic being: if Roman then signs one of
      these artificially-created paintings, does it become
      his work, as if he’d created it by his own hand? Why
      not?

      How far removed is work made by AIR from Andy
      Warhol’s soup can screenprints?

      If a good artist imitates and a great artist
      steals, wouldn’t a computer program designed
      to steal be the greatest artist ever?

      When an artist's work can be fed through a machine
      that understands it and produces new work to rival
      the quality of the original, can we program artistic
      sensibility into it too? And can it then produce its
      “own” work?

      Humans create art to start dialogues, to provoke, to
      speak. Can something that doesn’t have human-like
      emotional intelligence ever produce something really
      worthy of the title art?

      If you saw a piece of work in a gallery and the
      artist that had created it was none other than the
      RothkoBot 3000, would the cold, silicon mind behind
      it devalue the work, in your eyes? The work produced
      an emotional response: maybe the fleshiness of the
      creator doesn't even matter.

      And just think of the investment opportunities: maybe
      a robot’s art would increase in value every time it
      gets a firmware update. What if the artwork itself was
      updated over-the-air every now and then?

      AI-produced art triggers a huge number of hard
      questions - but not all of them are rhetorical, so
      feel free to whip the above puzzlers out at dinner
      parties to try and one-up whoever’s hosting.

      Our motto: Artpocalypse Now!

      Maybe we should all accept our fate, and get ready to
      embrace a future where art is better, cheaper, and
      everywhere.

      After all, AI is going to be better than us humans at
      almost everything, and if it’s better than us at the
      most human expression of all, then hook me the fuck
      up. Walter Benjamin, eat your heart out.
     </div>
   </div>
 </body>
</html>
